{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-11T22:11:02.799289Z","iopub.execute_input":"2022-12-11T22:11:02.800055Z","iopub.status.idle":"2022-12-11T22:11:02.835887Z","shell.execute_reply.started":"2022-12-11T22:11:02.799964Z","shell.execute_reply":"2022-12-11T22:11:02.834797Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/fraud-detection/fraudTest.csv\n/kaggle/input/fraud-detection/fraudTrain.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\nimport torch\nfrom sklearn.model_selection import train_test_split\n\npd.set_option('display.max_columns', None)\nsns.set(rc = {'figure.figsize':(15,8)})","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:11:03.992834Z","iopub.execute_input":"2022-12-11T22:11:03.993199Z","iopub.status.idle":"2022-12-11T22:11:04.995776Z","shell.execute_reply.started":"2022-12-11T22:11:03.993168Z","shell.execute_reply":"2022-12-11T22:11:04.994839Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"SEED = 42\n\nif torch.cuda.is_available():\n    DEVICE = \"cuda\" \nelse:\n    DEVICE = \"cpu\"\nprint(\"Selected device is\",DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:11:04.997853Z","iopub.execute_input":"2022-12-11T22:11:04.998653Z","iopub.status.idle":"2022-12-11T22:11:05.074965Z","shell.execute_reply.started":"2022-12-11T22:11:04.998605Z","shell.execute_reply":"2022-12-11T22:11:05.073594Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Selected device is cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv('../input/fraud-detection/fraudTrain.csv')\ndf.drop_duplicates(inplace=True)\ndf = df.drop('Unnamed: 0', axis=1)\ndf['age']=dt.date.today().year-pd.to_datetime(df['dob']).dt.year\ndf['hour']=pd.to_datetime(df['trans_date_trans_time']).dt.hour\ndf['daily']=pd.to_datetime(df['trans_date_trans_time']).dt.day\ndf['day']=pd.to_datetime(df['trans_date_trans_time']).dt.dayofweek\ndf['month']=pd.to_datetime(df['trans_date_trans_time']).dt.month","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:20.740180Z","iopub.execute_input":"2022-12-11T22:37:20.740888Z","iopub.status.idle":"2022-12-11T22:37:30.297692Z","shell.execute_reply.started":"2022-12-11T22:37:20.740850Z","shell.execute_reply":"2022-12-11T22:37:30.296690Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf['category_encoded'] = labelencoder.fit_transform(df['category'])\ndf['gender_encoded'] = labelencoder.fit_transform(df['gender'])\ndf['city_encoded'] = labelencoder.fit_transform(df['city'])\ndf['state_encoded'] =labelencoder.fit_transform(df['state'])\ndf['job_encoded'] = labelencoder.fit_transform(df['job'])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:30.299708Z","iopub.execute_input":"2022-12-11T22:37:30.300094Z","iopub.status.idle":"2022-12-11T22:37:31.898070Z","shell.execute_reply.started":"2022-12-11T22:37:30.300057Z","shell.execute_reply":"2022-12-11T22:37:31.897125Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"X = df[['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month', 'is_fraud']]\ninput_features = ['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month']","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:31.899619Z","iopub.execute_input":"2022-12-11T22:37:31.899982Z","iopub.status.idle":"2022-12-11T22:37:32.039513Z","shell.execute_reply.started":"2022-12-11T22:37:31.899944Z","shell.execute_reply":"2022-12-11T22:37:32.038542Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"df_train, df_val = train_test_split(X, test_size=0.1, random_state=42, stratify=X['is_fraud'])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:32.042210Z","iopub.execute_input":"2022-12-11T22:37:32.042626Z","iopub.status.idle":"2022-12-11T22:37:32.538926Z","shell.execute_reply.started":"2022-12-11T22:37:32.042588Z","shell.execute_reply":"2022-12-11T22:37:32.537967Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\nscaler.fit(df_train[input_features])\n\ndf_train[input_features]=scaler.transform(df_train[input_features])\ndf_val[input_features]=scaler.transform(df_val[input_features])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:32.540405Z","iopub.execute_input":"2022-12-11T22:37:32.540777Z","iopub.status.idle":"2022-12-11T22:37:33.106072Z","shell.execute_reply.started":"2022-12-11T22:37:32.540740Z","shell.execute_reply":"2022-12-11T22:37:33.105084Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.iloc[:,:-1]\ny_train = df_train.iloc[:,-1]\nX_val = df_val.iloc[:,:-1]\ny_val = df_val.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.107719Z","iopub.execute_input":"2022-12-11T22:37:33.108118Z","iopub.status.idle":"2022-12-11T22:37:33.189983Z","shell.execute_reply.started":"2022-12-11T22:37:33.108079Z","shell.execute_reply":"2022-12-11T22:37:33.189009Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"X_train_torch = torch.FloatTensor(X_train.values)\nX_val_torch = torch.FloatTensor(X_val.values)\ny_train_torch = torch.FloatTensor(y_train.values)\ny_val_torch = torch.FloatTensor(y_val.values)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.191383Z","iopub.execute_input":"2022-12-11T22:37:33.191940Z","iopub.status.idle":"2022-12-11T22:37:33.314541Z","shell.execute_reply.started":"2022-12-11T22:37:33.191902Z","shell.execute_reply":"2022-12-11T22:37:33.313552Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class FraudDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, x,output=True):\n        'Initialization'\n        self.x = x\n        self.output = output\n\n    def __len__(self):\n        'Returns the total number of samples'\n        return len(self.x)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample index\n        item = self.x[index].to(DEVICE)\n        if self.output:\n            return item, item\n        else:\n            return item","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.315950Z","iopub.execute_input":"2022-12-11T22:37:33.316627Z","iopub.status.idle":"2022-12-11T22:37:33.323742Z","shell.execute_reply.started":"2022-12-11T22:37:33.316589Z","shell.execute_reply":"2022-12-11T22:37:33.322593Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"train_set = FraudDataset(X_train_torch)\nval_set = FraudDataset(X_val_torch)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.325362Z","iopub.execute_input":"2022-12-11T22:37:33.325728Z","iopub.status.idle":"2022-12-11T22:37:33.337944Z","shell.execute_reply.started":"2022-12-11T22:37:33.325692Z","shell.execute_reply":"2022-12-11T22:37:33.337079Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_loader_params = {'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 0}\nvalid_loader_params = {'batch_size': 64,\n              'num_workers': 0}\n    \ntraining_generator = torch.utils.data.DataLoader(train_set, **train_loader_params)\nvalid_generator = torch.utils.data.DataLoader(val_set, **valid_loader_params)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.342575Z","iopub.execute_input":"2022-12-11T22:37:33.342922Z","iopub.status.idle":"2022-12-11T22:37:33.353378Z","shell.execute_reply.started":"2022-12-11T22:37:33.342876Z","shell.execute_reply":"2022-12-11T22:37:33.352504Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class Autoencoder(torch.nn.Module):\n    \n        def __init__(self, input_size, intermediate_size, code_size):\n            super(Autoencoder, self).__init__()\n            # parameters\n            self.input_size = input_size\n            self.intermediate_size = intermediate_size           \n            self.code_size  = code_size\n            \n            self.relu = torch.nn.ReLU()   \n            \n            #encoder\n            self.fc1 = torch.nn.Linear(self.input_size, self.intermediate_size)\n            self.fc2 = torch.nn.Linear(self.intermediate_size, self.code_size)\n            \n            #decoder \n            self.fc3 = torch.nn.Linear(self.code_size, self.intermediate_size)            \n            self.fc4 = torch.nn.Linear(self.intermediate_size, self.input_size)\n            \n            \n        def forward(self, x):\n            \n            hidden = self.fc1(x)\n            hidden = self.relu(hidden)\n            \n            code = self.fc2(hidden)\n            code = self.relu(code)\n \n            hidden = self.fc3(code)\n            hidden = self.relu(hidden)\n            \n            output = self.fc4(hidden)\n            #linear activation in final layer)            \n            \n            return output","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.354905Z","iopub.execute_input":"2022-12-11T22:37:33.355391Z","iopub.status.idle":"2022-12-11T22:37:33.365207Z","shell.execute_reply.started":"2022-12-11T22:37:33.355353Z","shell.execute_reply":"2022-12-11T22:37:33.364253Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.MSELoss().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.366441Z","iopub.execute_input":"2022-12-11T22:37:33.366860Z","iopub.status.idle":"2022-12-11T22:37:33.378912Z","shell.execute_reply.started":"2022-12-11T22:37:33.366826Z","shell.execute_reply":"2022-12-11T22:37:33.378003Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"def per_sample_mse(model, generator):\n    \n    model.eval()\n    criterion = torch.nn.MSELoss(reduction=\"none\")\n    batch_losses = []\n    \n    for x_batch, y_batch in generator:\n        # Forward pass\n        y_pred = model(x_batch)\n        # Compute Loss\n        loss = criterion(y_pred.squeeze(), y_batch)\n        loss_app = list(torch.mean(loss,axis=1).detach().cpu().numpy())\n        batch_losses.extend(loss_app)\n    \n    return batch_losses","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.381484Z","iopub.execute_input":"2022-12-11T22:37:33.381769Z","iopub.status.idle":"2022-12-11T22:37:33.390864Z","shell.execute_reply.started":"2022-12-11T22:37:33.381744Z","shell.execute_reply":"2022-12-11T22:37:33.389965Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder(X_train.shape[1], 200, 20).to(DEVICE)\nlosses = per_sample_mse(model, valid_generator)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:33.393095Z","iopub.execute_input":"2022-12-11T22:37:33.394108Z","iopub.status.idle":"2022-12-11T22:37:37.294884Z","shell.execute_reply.started":"2022-12-11T22:37:33.394022Z","shell.execute_reply":"2022-12-11T22:37:37.293859Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"print(losses[0:5])\nprint(np.mean(losses))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:40.066630Z","iopub.execute_input":"2022-12-11T22:37:40.066998Z","iopub.status.idle":"2022-12-11T22:37:40.078954Z","shell.execute_reply.started":"2022-12-11T22:37:40.066967Z","shell.execute_reply":"2022-12-11T22:37:40.077741Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"[0.6762004, 0.98505133, 1.1826674, 0.44613016, 0.6240214]\n1.0510426\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Autoencoder(len(input_features), 200, 20).to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:42.409748Z","iopub.execute_input":"2022-12-11T22:37:42.410178Z","iopub.status.idle":"2022-12-11T22:37:42.422360Z","shell.execute_reply.started":"2022-12-11T22:37:42.410140Z","shell.execute_reply":"2022-12-11T22:37:42.421453Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"import time\ndef training_loop(model,training_generator,valid_generator,optimizer,criterion,max_epochs=100,apply_early_stopping=True,patience=4,verbose=False):\n    #Setting the model in training mode\n    model.train()\n\n    if apply_early_stopping:\n        early_stopping = EarlyStopping(verbose=verbose,patience=patience)\n    \n    all_train_losses = []\n    all_valid_losses = []\n    \n    #Training loop\n    start_time=time.time()\n    for epoch in range(max_epochs):\n        model.train()\n        train_loss=[]\n        for x_batch, y_batch in training_generator:\n            optimizer.zero_grad()\n            # Forward pass\n            y_pred = model(x_batch)\n            # Compute Loss\n            loss = criterion(y_pred.squeeze(), y_batch)\n            # Backward pass\n            loss.backward()\n            optimizer.step()   \n            train_loss.append(loss.item())\n        \n        #showing last training loss after each epoch\n        all_train_losses.append(np.mean(train_loss))\n        if verbose:\n            print('')\n            print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n        #evaluating the model on the test set after each epoch    \n        valid_loss = evaluate_model(model,valid_generator,criterion)\n        all_valid_losses.append(valid_loss)\n        if verbose:\n            print('valid loss: {}'.format(valid_loss))\n        if apply_early_stopping:\n            if not early_stopping.continue_training(valid_loss):\n                if verbose:\n                    print(\"Early stopping\")\n                break\n        \n    training_execution_time=time.time()-start_time\n    return model,training_execution_time,all_train_losses,all_valid_losses\n\nclass EarlyStopping:\n    \n    def __init__(self, patience=6, verbose=False):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = np.Inf\n    \n    def continue_training(self,current_score):\n        if self.best_score > current_score:\n            self.best_score = current_score\n            self.counter = 0\n            if self.verbose:\n                print(\"New best score:\", current_score)\n        else:\n            self.counter+=1\n            if self.verbose:\n                print(self.counter, \" iterations since best score.\")\n                \n        return self.counter <= self.patience \n\ndef evaluate_model(model,generator,criterion):\n    model.eval()\n    batch_losses = []\n    for x_batch, y_batch in generator:\n        # Forward pass\n        y_pred = model(x_batch)\n        # Compute Loss\n        loss = criterion(y_pred.squeeze(), y_batch)\n        batch_losses.append(loss.item())\n    mean_loss = np.mean(batch_losses)    \n    return mean_loss","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:37:43.989063Z","iopub.execute_input":"2022-12-11T22:37:43.989453Z","iopub.status.idle":"2022-12-11T22:37:44.005848Z","shell.execute_reply.started":"2022-12-11T22:37:43.989416Z","shell.execute_reply":"2022-12-11T22:37:44.004864Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model,training_execution_time,train_losses,valid_losses = training_loop(model,\n                                                                        training_generator,\n                                                                        valid_generator,\n                                                                        optimizer,\n                                                                        criterion,\n                                                                        max_epochs=500,\n                                                                        patience=2,\n                                                                        verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:38:22.830923Z","iopub.execute_input":"2022-12-11T22:38:22.831404Z","iopub.status.idle":"2022-12-11T22:40:57.748205Z","shell.execute_reply.started":"2022-12-11T22:38:22.831363Z","shell.execute_reply":"2022-12-11T22:40:57.746484Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"\nEpoch 0: train loss: 0.0008532465994741911\nvalid loss: 0.00014257329165789982\nNew best score: 0.00014257329165789982\n\nEpoch 1: train loss: 0.0001308609646210364\nvalid loss: 2.1291473124453633e-05\nNew best score: 2.1291473124453633e-05\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3715296612.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                         \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                         \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                                         verbose=True)\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_23/1732801287.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, training_generator, valid_generator, optimizer, criterion, max_epochs, apply_early_stopping, patience, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"losses = per_sample_mse(model, valid_generator)\nprint(losses[0:5])\nprint(np.mean(losses))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:00.604430Z","iopub.execute_input":"2022-12-11T22:41:00.604785Z","iopub.status.idle":"2022-12-11T22:41:04.147321Z","shell.execute_reply.started":"2022-12-11T22:41:00.604756Z","shell.execute_reply":"2022-12-11T22:41:04.145545Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"[3.0029973e-06, 2.7826652e-06, 9.516395e-06, 1.2725758e-06, 4.191075e-06]\n6.0822986e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"genuine_losses = np.array(losses)[y_val_torch.cpu().numpy() == 0]\nfraud_losses = np.array(losses)[y_val_torch.cpu().numpy() == 1]\nprint(\"Average fraud reconstruction error:\", np.mean(fraud_losses))\nprint(\"Average genuine reconstruction error:\", np.mean(genuine_losses))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:05.895651Z","iopub.execute_input":"2022-12-11T22:41:05.896672Z","iopub.status.idle":"2022-12-11T22:41:05.919457Z","shell.execute_reply.started":"2022-12-11T22:41:05.896623Z","shell.execute_reply":"2022-12-11T22:41:05.918364Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Average fraud reconstruction error: 4.955523e-05\nAverage genuine reconstruction error: 5.8290498e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions_df=df_val\npredictions_df['predictions']=losses","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:07.591355Z","iopub.execute_input":"2022-12-11T22:41:07.591713Z","iopub.status.idle":"2022-12-11T22:41:07.620713Z","shell.execute_reply.started":"2022-12-11T22:41:07.591681Z","shell.execute_reply":"2022-12-11T22:41:07.619737Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"predictions_df","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:09.289902Z","iopub.execute_input":"2022-12-11T22:41:09.290799Z","iopub.status.idle":"2022-12-11T22:41:09.315877Z","shell.execute_reply.started":"2022-12-11T22:41:09.290750Z","shell.execute_reply":"2022-12-11T22:41:09.314807Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n295133          -0.568910  0.216224       -0.909987     -0.337550   \n309036           0.197485 -0.231450        1.098917      1.251784   \n877558          -1.590770  0.604477       -0.909987      1.429666   \n696676          -0.313445 -0.098344       -0.909987      0.215430   \n351866          -1.079840 -0.087470        1.098917      1.688754   \n...                   ...       ...             ...           ...   \n1115045         -1.590770  0.142411       -0.909987      1.124173   \n81445           -0.057980  0.372293       -0.909987      0.996563   \n1105080         -0.568910  0.283193        1.098917      0.192228   \n838805           0.452949 -0.405876       -0.909987     -1.478312   \n1155691          1.219344  0.181556        1.098917     -0.399422   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n295133        0.929411 -0.248573    -1.206866  1.395357 -0.851290  1.065584   \n309036       -1.164268 -0.264084     1.555412  0.244683  1.348840  1.518580   \n877558        1.138779  0.183478     1.291318 -0.618322  1.202164  0.612587   \n696676        1.138779 -0.285640     0.634652  0.187150  0.615463  0.952334   \n351866        1.557515 -0.275749    -0.457411 -0.388187 -0.411264 -0.180158   \n...                ...       ...          ...       ...       ...       ...   \n1115045      -0.466375 -0.292969    -0.007738 -0.158052  0.908814 -0.859653   \n81445         1.138779 -0.233963    -0.086252 -0.963524  1.495515  0.159590   \n1105080      -0.187218 -0.290813     1.583962 -0.042985 -1.291316 -1.199400   \n838805        0.999200 -0.267485    -0.136216  1.913160 -0.704615 -0.293407   \n1155691      -1.583003 -0.293599    -0.814294  0.014549 -0.997965  1.292082   \n\n              day     month  is_fraud  predictions  \n295133   0.877664 -0.334296         0     0.000003  \n309036  -0.486978 -0.334296         0     0.000003  \n877558   0.877664  1.714365         0     0.000010  \n696676  -0.032098  1.129033         0     0.000001  \n351866   0.422783 -0.041631         0     0.000004  \n...           ...       ...       ...          ...  \n1115045 -0.486978 -0.626962         0     0.000001  \n81445    1.332544 -1.212294         0     0.000004  \n1105080  1.332544 -0.626962         0     0.000001  \n838805   0.422783  1.714365         0     0.000003  \n1155691 -1.396740 -0.626962         0     0.000002  \n\n[129668 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295133</th>\n      <td>-0.568910</td>\n      <td>0.216224</td>\n      <td>-0.909987</td>\n      <td>-0.337550</td>\n      <td>0.929411</td>\n      <td>-0.248573</td>\n      <td>-1.206866</td>\n      <td>1.395357</td>\n      <td>-0.851290</td>\n      <td>1.065584</td>\n      <td>0.877664</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>309036</th>\n      <td>0.197485</td>\n      <td>-0.231450</td>\n      <td>1.098917</td>\n      <td>1.251784</td>\n      <td>-1.164268</td>\n      <td>-0.264084</td>\n      <td>1.555412</td>\n      <td>0.244683</td>\n      <td>1.348840</td>\n      <td>1.518580</td>\n      <td>-0.486978</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>877558</th>\n      <td>-1.590770</td>\n      <td>0.604477</td>\n      <td>-0.909987</td>\n      <td>1.429666</td>\n      <td>1.138779</td>\n      <td>0.183478</td>\n      <td>1.291318</td>\n      <td>-0.618322</td>\n      <td>1.202164</td>\n      <td>0.612587</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <th>696676</th>\n      <td>-0.313445</td>\n      <td>-0.098344</td>\n      <td>-0.909987</td>\n      <td>0.215430</td>\n      <td>1.138779</td>\n      <td>-0.285640</td>\n      <td>0.634652</td>\n      <td>0.187150</td>\n      <td>0.615463</td>\n      <td>0.952334</td>\n      <td>-0.032098</td>\n      <td>1.129033</td>\n      <td>0</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>351866</th>\n      <td>-1.079840</td>\n      <td>-0.087470</td>\n      <td>1.098917</td>\n      <td>1.688754</td>\n      <td>1.557515</td>\n      <td>-0.275749</td>\n      <td>-0.457411</td>\n      <td>-0.388187</td>\n      <td>-0.411264</td>\n      <td>-0.180158</td>\n      <td>0.422783</td>\n      <td>-0.041631</td>\n      <td>0</td>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1115045</th>\n      <td>-1.590770</td>\n      <td>0.142411</td>\n      <td>-0.909987</td>\n      <td>1.124173</td>\n      <td>-0.466375</td>\n      <td>-0.292969</td>\n      <td>-0.007738</td>\n      <td>-0.158052</td>\n      <td>0.908814</td>\n      <td>-0.859653</td>\n      <td>-0.486978</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>81445</th>\n      <td>-0.057980</td>\n      <td>0.372293</td>\n      <td>-0.909987</td>\n      <td>0.996563</td>\n      <td>1.138779</td>\n      <td>-0.233963</td>\n      <td>-0.086252</td>\n      <td>-0.963524</td>\n      <td>1.495515</td>\n      <td>0.159590</td>\n      <td>1.332544</td>\n      <td>-1.212294</td>\n      <td>0</td>\n      <td>0.000004</td>\n    </tr>\n    <tr>\n      <th>1105080</th>\n      <td>-0.568910</td>\n      <td>0.283193</td>\n      <td>1.098917</td>\n      <td>0.192228</td>\n      <td>-0.187218</td>\n      <td>-0.290813</td>\n      <td>1.583962</td>\n      <td>-0.042985</td>\n      <td>-1.291316</td>\n      <td>-1.199400</td>\n      <td>1.332544</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000001</td>\n    </tr>\n    <tr>\n      <th>838805</th>\n      <td>0.452949</td>\n      <td>-0.405876</td>\n      <td>-0.909987</td>\n      <td>-1.478312</td>\n      <td>0.999200</td>\n      <td>-0.267485</td>\n      <td>-0.136216</td>\n      <td>1.913160</td>\n      <td>-0.704615</td>\n      <td>-0.293407</td>\n      <td>0.422783</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>1155691</th>\n      <td>1.219344</td>\n      <td>0.181556</td>\n      <td>1.098917</td>\n      <td>-0.399422</td>\n      <td>-1.583003</td>\n      <td>-0.293599</td>\n      <td>-0.814294</td>\n      <td>0.014549</td>\n      <td>-0.997965</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000002</td>\n    </tr>\n  </tbody>\n</table>\n<p>129668 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.roc_auc_score(predictions_df[\"is_fraud\"], predictions_df[\"predictions\"]))\n\nprint(metrics.average_precision_score(predictions_df[\"is_fraud\"], predictions_df[\"predictions\"]))","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:09.731651Z","iopub.execute_input":"2022-12-11T22:41:09.732008Z","iopub.status.idle":"2022-12-11T22:41:09.794180Z","shell.execute_reply.started":"2022-12-11T22:41:09.731978Z","shell.execute_reply":"2022-12-11T22:41:09.792198Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"0.8805869551365572\n0.11018754150552329\n","output_type":"stream"}]},{"cell_type":"code","source":"metrics.average_precision_score(predictions_df[\"is_fraud\"], predictions_df[\"predictions\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:14.154540Z","iopub.execute_input":"2022-12-11T22:41:14.155465Z","iopub.status.idle":"2022-12-11T22:41:14.188006Z","shell.execute_reply.started":"2022-12-11T22:41:14.155426Z","shell.execute_reply":"2022-12-11T22:41:14.186969Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"0.11018754150552329"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df[predictions_df['is_fraud'] == 1]","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:41:40.192715Z","iopub.execute_input":"2022-12-11T22:41:40.193097Z","iopub.status.idle":"2022-12-11T22:41:40.222902Z","shell.execute_reply.started":"2022-12-11T22:41:40.193063Z","shell.execute_reply":"2022-12-11T22:41:40.221695Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n1062627          0.452949  4.428480        1.098917      0.838016   \n4808            -0.824375 -0.357712        1.098917      1.499272   \n207924           1.219344  5.054546        1.098917     -0.588904   \n93788           -0.568910  1.602485       -0.909987      0.752942   \n197243          -0.568910  1.596217       -0.909987      0.161292   \n...                   ...       ...             ...           ...   \n975620           1.219344  6.462298        1.098917      1.491538   \n554183          -0.568910  1.445329       -0.909987      0.942425   \n522167           1.219344  5.613003        1.098917      1.112572   \n908990           0.197485 -0.407987        1.098917     -1.296564   \n1157944          1.219344  6.870572       -0.909987      1.031365   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n1062627      -0.815321 -0.293552     0.249218  0.359751  1.495515  0.046341   \n4808         -1.862160 -0.293526    -1.727916  1.970694 -1.878017 -1.312649   \n207924        1.138779 -0.137939    -0.785743  0.474818  1.495515 -0.066908   \n93788         0.510675 -0.279330    -1.064112  2.776166 -1.437991  1.065584   \n197243        1.138779 -0.288074    -0.999873  0.474818  1.495515 -0.519905   \n...                ...       ...          ...       ...       ...       ...   \n975620       -1.583003 -0.293582    -0.771468  0.417285  1.495515  1.631829   \n554183        0.929411 -0.283526    -0.421722  0.704953 -1.878017  1.065584   \n522167        0.789833 -0.291280    -0.314657 -0.503254  1.348840 -0.406656   \n908990        0.650254 -0.292446     1.319869  1.855627  1.348840  1.405331   \n1157944       1.138779 -0.290919     0.613239  1.107689  1.348840  1.292082   \n\n              day     month  is_fraud  predictions  \n1062627 -1.396740 -0.919628         1     0.000031  \n4808     0.422783 -1.504960         1     0.000003  \n207924  -1.396740 -0.626962         1     0.000049  \n93788   -1.396740 -1.212294         1     0.000036  \n197243  -0.032098 -0.626962         1     0.000016  \n...           ...       ...       ...          ...  \n975620  -0.032098 -1.504960         1     0.000202  \n554183   1.332544  0.543701         1     0.000014  \n522167  -1.396740  0.543701         1     0.000065  \n908990   0.877664  1.714365         1     0.000005  \n1157944 -1.396740 -0.626962         1     0.000101  \n\n[751 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1062627</th>\n      <td>0.452949</td>\n      <td>4.428480</td>\n      <td>1.098917</td>\n      <td>0.838016</td>\n      <td>-0.815321</td>\n      <td>-0.293552</td>\n      <td>0.249218</td>\n      <td>0.359751</td>\n      <td>1.495515</td>\n      <td>0.046341</td>\n      <td>-1.396740</td>\n      <td>-0.919628</td>\n      <td>1</td>\n      <td>0.000031</td>\n    </tr>\n    <tr>\n      <th>4808</th>\n      <td>-0.824375</td>\n      <td>-0.357712</td>\n      <td>1.098917</td>\n      <td>1.499272</td>\n      <td>-1.862160</td>\n      <td>-0.293526</td>\n      <td>-1.727916</td>\n      <td>1.970694</td>\n      <td>-1.878017</td>\n      <td>-1.312649</td>\n      <td>0.422783</td>\n      <td>-1.504960</td>\n      <td>1</td>\n      <td>0.000003</td>\n    </tr>\n    <tr>\n      <th>207924</th>\n      <td>1.219344</td>\n      <td>5.054546</td>\n      <td>1.098917</td>\n      <td>-0.588904</td>\n      <td>1.138779</td>\n      <td>-0.137939</td>\n      <td>-0.785743</td>\n      <td>0.474818</td>\n      <td>1.495515</td>\n      <td>-0.066908</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>1</td>\n      <td>0.000049</td>\n    </tr>\n    <tr>\n      <th>93788</th>\n      <td>-0.568910</td>\n      <td>1.602485</td>\n      <td>-0.909987</td>\n      <td>0.752942</td>\n      <td>0.510675</td>\n      <td>-0.279330</td>\n      <td>-1.064112</td>\n      <td>2.776166</td>\n      <td>-1.437991</td>\n      <td>1.065584</td>\n      <td>-1.396740</td>\n      <td>-1.212294</td>\n      <td>1</td>\n      <td>0.000036</td>\n    </tr>\n    <tr>\n      <th>197243</th>\n      <td>-0.568910</td>\n      <td>1.596217</td>\n      <td>-0.909987</td>\n      <td>0.161292</td>\n      <td>1.138779</td>\n      <td>-0.288074</td>\n      <td>-0.999873</td>\n      <td>0.474818</td>\n      <td>1.495515</td>\n      <td>-0.519905</td>\n      <td>-0.032098</td>\n      <td>-0.626962</td>\n      <td>1</td>\n      <td>0.000016</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>975620</th>\n      <td>1.219344</td>\n      <td>6.462298</td>\n      <td>1.098917</td>\n      <td>1.491538</td>\n      <td>-1.583003</td>\n      <td>-0.293582</td>\n      <td>-0.771468</td>\n      <td>0.417285</td>\n      <td>1.495515</td>\n      <td>1.631829</td>\n      <td>-0.032098</td>\n      <td>-1.504960</td>\n      <td>1</td>\n      <td>0.000202</td>\n    </tr>\n    <tr>\n      <th>554183</th>\n      <td>-0.568910</td>\n      <td>1.445329</td>\n      <td>-0.909987</td>\n      <td>0.942425</td>\n      <td>0.929411</td>\n      <td>-0.283526</td>\n      <td>-0.421722</td>\n      <td>0.704953</td>\n      <td>-1.878017</td>\n      <td>1.065584</td>\n      <td>1.332544</td>\n      <td>0.543701</td>\n      <td>1</td>\n      <td>0.000014</td>\n    </tr>\n    <tr>\n      <th>522167</th>\n      <td>1.219344</td>\n      <td>5.613003</td>\n      <td>1.098917</td>\n      <td>1.112572</td>\n      <td>0.789833</td>\n      <td>-0.291280</td>\n      <td>-0.314657</td>\n      <td>-0.503254</td>\n      <td>1.348840</td>\n      <td>-0.406656</td>\n      <td>-1.396740</td>\n      <td>0.543701</td>\n      <td>1</td>\n      <td>0.000065</td>\n    </tr>\n    <tr>\n      <th>908990</th>\n      <td>0.197485</td>\n      <td>-0.407987</td>\n      <td>1.098917</td>\n      <td>-1.296564</td>\n      <td>0.650254</td>\n      <td>-0.292446</td>\n      <td>1.319869</td>\n      <td>1.855627</td>\n      <td>1.348840</td>\n      <td>1.405331</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>1</td>\n      <td>0.000005</td>\n    </tr>\n    <tr>\n      <th>1157944</th>\n      <td>1.219344</td>\n      <td>6.870572</td>\n      <td>-0.909987</td>\n      <td>1.031365</td>\n      <td>1.138779</td>\n      <td>-0.290919</td>\n      <td>0.613239</td>\n      <td>1.107689</td>\n      <td>1.348840</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>1</td>\n      <td>0.000101</td>\n    </tr>\n  </tbody>\n</table>\n<p>751 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"metrics.classification_report(predictions_df[\"is_fraud\"], predictions_df[\"predictions\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-10T12:20:52.270310Z","iopub.execute_input":"2022-12-10T12:20:52.270683Z","iopub.status.idle":"2022-12-10T12:20:52.296368Z","shell.execute_reply.started":"2022-12-10T12:20:52.270649Z","shell.execute_reply":"2022-12-10T12:20:52.294955Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3118779504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_fraud\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"],"ename":"ValueError","evalue":"Classification metrics can't handle a mix of binary and continuous targets","output_type":"error"}]},{"cell_type":"code","source":"predictions_df['predictions'].apply(torch.nn.Sigmoid())","metadata":{"execution":{"iopub.status.busy":"2022-12-10T12:20:52.727771Z","iopub.execute_input":"2022-12-10T12:20:52.728140Z","iopub.status.idle":"2022-12-10T12:20:52.780028Z","shell.execute_reply.started":"2022-12-10T12:20:52.728108Z","shell.execute_reply":"2022-12-10T12:20:52.778455Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3744235046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: sigmoid(): argument 'input' (position 1) must be Tensor, not float"],"ename":"TypeError","evalue":"sigmoid(): argument 'input' (position 1) must be Tensor, not float","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\nanomalyclassifier = IsolationForest(random_state=SEED, n_estimators=40)\nanomalyclassifier.fit(df_train[input_features])","metadata":{"execution":{"iopub.status.busy":"2022-12-10T12:21:04.944251Z","iopub.execute_input":"2022-12-10T12:21:04.944614Z","iopub.status.idle":"2022-12-10T12:21:08.339557Z","shell.execute_reply.started":"2022-12-10T12:21:04.944582Z","shell.execute_reply":"2022-12-10T12:21:08.338373Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"IsolationForest(n_estimators=40, random_state=42)"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df = df_val\npredictions_df['predictions'] = -anomalyclassifier.score_samples(df_val[input_features])","metadata":{"execution":{"iopub.status.busy":"2022-12-10T12:21:08.341933Z","iopub.execute_input":"2022-12-10T12:21:08.342295Z","iopub.status.idle":"2022-12-10T12:21:09.848766Z","shell.execute_reply.started":"2022-12-10T12:21:08.342258Z","shell.execute_reply":"2022-12-10T12:21:09.847735Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"metrics.roc_auc_score(predictions_df[\"is_fraud\"], predictions_df[\"predictions\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-10T12:21:09.850006Z","iopub.execute_input":"2022-12-10T12:21:09.850322Z","iopub.status.idle":"2022-12-10T12:21:09.891506Z","shell.execute_reply.started":"2022-12-10T12:21:09.850293Z","shell.execute_reply":"2022-12-10T12:21:09.890395Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0.8566069207897851"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}