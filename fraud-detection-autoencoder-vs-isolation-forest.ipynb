{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\nimport torch\nfrom sklearn.model_selection import train_test_split\n\npd.set_option('display.max_columns', None)\nsns.set(rc = {'figure.figsize':(15,8)})\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-11T11:51:35.769763Z","iopub.execute_input":"2023-02-11T11:51:35.770898Z","iopub.status.idle":"2023-02-11T11:51:35.791847Z","shell.execute_reply.started":"2023-02-11T11:51:35.770841Z","shell.execute_reply":"2023-02-11T11:51:35.789299Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/fraud-detection/fraudTest.csv\n/kaggle/input/fraud-detection/fraudTrain.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 42\n\nif torch.cuda.is_available():\n    DEVICE = \"cuda\" \nelse:\n    DEVICE = \"cpu\"\nprint(\"Selected device is\",DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T11:51:35.795028Z","iopub.execute_input":"2023-02-11T11:51:35.795659Z","iopub.status.idle":"2023-02-11T11:51:35.807713Z","shell.execute_reply.started":"2023-02-11T11:51:35.795606Z","shell.execute_reply":"2023-02-11T11:51:35.806207Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Selected device is cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading and preprocessing the data ","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/fraud-detection/fraudTrain.csv')\ndf.drop_duplicates(inplace=True)\ndf = df.drop('Unnamed: 0', axis=1)\ndf['age']=dt.date.today().year-pd.to_datetime(df['dob']).dt.year\ndf['hour']=pd.to_datetime(df['trans_date_trans_time']).dt.hour\ndf['daily']=pd.to_datetime(df['trans_date_trans_time']).dt.day\ndf['day']=pd.to_datetime(df['trans_date_trans_time']).dt.dayofweek\ndf['month']=pd.to_datetime(df['trans_date_trans_time']).dt.month","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:01:22.339582Z","iopub.execute_input":"2023-02-11T13:01:22.340510Z","iopub.status.idle":"2023-02-11T13:01:37.736510Z","shell.execute_reply.started":"2023-02-11T13:01:22.340403Z","shell.execute_reply":"2023-02-11T13:01:37.735201Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf['category_encoded'] = labelencoder.fit_transform(df['category'])\ndf['gender_encoded'] = labelencoder.fit_transform(df['gender'])\ndf['city_encoded'] = labelencoder.fit_transform(df['city'])\ndf['state_encoded'] =labelencoder.fit_transform(df['state'])\ndf['job_encoded'] = labelencoder.fit_transform(df['job'])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:01:37.741557Z","iopub.execute_input":"2023-02-11T13:01:37.742547Z","iopub.status.idle":"2023-02-11T13:01:39.443636Z","shell.execute_reply.started":"2023-02-11T13:01:37.742495Z","shell.execute_reply":"2023-02-11T13:01:39.442046Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"X = df[['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month', 'is_fraud']]\ninput_features = ['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month']","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:01:39.446028Z","iopub.execute_input":"2023-02-11T13:01:39.446645Z","iopub.status.idle":"2023-02-11T13:01:39.627232Z","shell.execute_reply.started":"2023-02-11T13:01:39.446587Z","shell.execute_reply":"2023-02-11T13:01:39.625880Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"#### Spliting the training set into training (90%) and validation(10%) set","metadata":{}},{"cell_type":"code","source":"df_train, df_val = train_test_split(X, test_size=0.1, random_state=42, stratify=X['is_fraud'])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:31:54.390367Z","iopub.execute_input":"2023-02-11T13:31:54.390984Z","iopub.status.idle":"2023-02-11T13:31:55.171437Z","shell.execute_reply.started":"2023-02-11T13:31:54.390937Z","shell.execute_reply":"2023-02-11T13:31:55.170086Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"markdown","source":"### We scale the data","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\nscaler.fit(df_train[input_features])\n\ndf_train[input_features]=scaler.transform(df_train[input_features])\ndf_val[input_features]=scaler.transform(df_val[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:03.784202Z","iopub.execute_input":"2023-02-11T13:32:03.784641Z","iopub.status.idle":"2023-02-11T13:32:04.487486Z","shell.execute_reply.started":"2023-02-11T13:32:03.784606Z","shell.execute_reply":"2023-02-11T13:32:04.485719Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.iloc[:,:-1]\ny_train = df_train.iloc[:,-1]\nX_val = df_val.iloc[:,:-1]\ny_val = df_val.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:01:41.202290Z","iopub.execute_input":"2023-02-11T13:01:41.203301Z","iopub.status.idle":"2023-02-11T13:01:41.300271Z","shell.execute_reply.started":"2023-02-11T13:01:41.203250Z","shell.execute_reply":"2023-02-11T13:01:41.298740Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"markdown","source":"### We convert our features and labels into torch tensors","metadata":{}},{"cell_type":"code","source":"X_train_torch = torch.FloatTensor(X_train.values)\nX_val_torch = torch.FloatTensor(X_val.values)\ny_train_torch = torch.FloatTensor(y_train.values)\ny_val_torch = torch.FloatTensor(y_val.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:01:41.302719Z","iopub.execute_input":"2023-02-11T13:01:41.303705Z","iopub.status.idle":"2023-02-11T13:01:41.471990Z","shell.execute_reply.started":"2023-02-11T13:01:41.303652Z","shell.execute_reply":"2023-02-11T13:01:41.470611Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"markdown","source":"#### As we all know that in case of fraud detection, companies do not always have a labeled historical data. So for this reason why we tried to rely on unsupervised learning models. We will also rely on a new dataset which receives the descriptive features of a transaction and returns it as both input and output","metadata":{}},{"cell_type":"code","source":"class FraudDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, x,output=True):\n        'Initialization'\n        self.x = x\n        self.output = output\n\n    def __len__(self):\n        'Returns the total number of samples'\n        return len(self.x)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        item = self.x[index].to(DEVICE)\n        if self.output:\n            return item, item\n        else:\n            return item","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:19.023398Z","iopub.execute_input":"2023-02-11T13:12:19.023847Z","iopub.status.idle":"2023-02-11T13:12:19.032875Z","shell.execute_reply.started":"2023-02-11T13:12:19.023808Z","shell.execute_reply":"2023-02-11T13:12:19.031349Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"train_set = FraudDataset(X_train_torch)\nval_set = FraudDataset(X_val_torch)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:19.403373Z","iopub.execute_input":"2023-02-11T13:12:19.403807Z","iopub.status.idle":"2023-02-11T13:12:19.412140Z","shell.execute_reply.started":"2023-02-11T13:12:19.403772Z","shell.execute_reply":"2023-02-11T13:12:19.410108Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"train_loader_params = {'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 0}\nvalid_loader_params = {'batch_size': 64,\n              'num_workers': 0}\n    \ntraining_generator = torch.utils.data.DataLoader(train_set, **train_loader_params)\nvalid_generator = torch.utils.data.DataLoader(val_set, **valid_loader_params)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:19.796131Z","iopub.execute_input":"2023-02-11T13:12:19.796555Z","iopub.status.idle":"2023-02-11T13:12:19.807559Z","shell.execute_reply.started":"2023-02-11T13:12:19.796520Z","shell.execute_reply":"2023-02-11T13:12:19.805952Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"markdown","source":"#### We resorted to a regular feed-forward autoencoder with the following architecture:\n* A first input layer with ReLu activation (input_size, intermediate_size)\n\n* A second layer with ReLu activation (intermediate_size, code_size)\n\n* A third layer with ReLu activation (code_size, intermediate_size)\n\n* An output layer with linear activation (intermediate_size, input_size)","metadata":{}},{"cell_type":"code","source":"class Autoencoder(torch.nn.Module):\n    \n        def __init__(self, input_size, intermediate_size, code_size):\n            super(Autoencoder, self).__init__()\n            # parameters\n            self.input_size = input_size\n            self.intermediate_size = intermediate_size           \n            self.code_size  = code_size\n            \n            self.relu = torch.nn.ReLU()   \n            \n            #encoder\n            self.fc1 = torch.nn.Linear(self.input_size, self.intermediate_size)\n            self.fc2 = torch.nn.Linear(self.intermediate_size, self.code_size)\n            \n            #decoder \n            self.fc3 = torch.nn.Linear(self.code_size, self.intermediate_size)            \n            self.fc4 = torch.nn.Linear(self.intermediate_size, self.input_size)\n            \n\n            \n            \n        def forward(self, x):\n            \n            hidden = self.fc1(x)\n            hidden = self.relu(hidden)\n            \n            code = self.fc2(hidden)\n            code = self.relu(code)\n \n            hidden = self.fc3(code)\n            hidden = self.relu(hidden)\n            \n            output = self.fc4(hidden)\n            \n            return output","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:21.038866Z","iopub.execute_input":"2023-02-11T13:12:21.039722Z","iopub.status.idle":"2023-02-11T13:12:21.052826Z","shell.execute_reply.started":"2023-02-11T13:12:21.039644Z","shell.execute_reply":"2023-02-11T13:12:21.050751Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.MSELoss().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:21.822697Z","iopub.execute_input":"2023-02-11T13:12:21.823957Z","iopub.status.idle":"2023-02-11T13:12:21.830963Z","shell.execute_reply.started":"2023-02-11T13:12:21.823901Z","shell.execute_reply":"2023-02-11T13:12:21.829631Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"markdown","source":"#### Our goal is to predict the input from the input. Therefore, one cannot directly use its prediction for fraud detection. Instead, the idea is to use its reconstruction error between the input and the output.\n\n#### the reconstruction error can be considered as predicted fraud score, and therfore the higher the error, the higher the risk.","metadata":{}},{"cell_type":"code","source":"def per_sample_mse(model, generator):\n    \n    model.eval()\n    criterion = torch.nn.MSELoss(reduction=\"none\")\n    batch_losses = []\n    \n    for x_batch, y_batch in generator:\n        # Forward pass\n        y_pred = model(x_batch)\n        # Compute Loss\n        loss = criterion(y_pred.squeeze(), y_batch)\n        loss_app = list(torch.mean(loss,axis=1).detach().cpu().numpy())\n        batch_losses.extend(loss_app)\n    \n    return batch_losses","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:22.527279Z","iopub.execute_input":"2023-02-11T13:12:22.528110Z","iopub.status.idle":"2023-02-11T13:12:22.537300Z","shell.execute_reply.started":"2023-02-11T13:12:22.528068Z","shell.execute_reply":"2023-02-11T13:12:22.535819Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"import time\ndef training_loop(model,training_generator,valid_generator,optimizer,criterion,max_epochs=100,apply_early_stopping=True,patience=4,verbose=False):\n    #Setting the model in training mode\n    model.train()\n\n    if apply_early_stopping:\n        early_stopping = EarlyStopping(verbose=verbose,patience=patience)\n    \n    all_train_losses = []\n    all_valid_losses = []\n    \n    #Training loop\n    start_time=time.time()\n    for epoch in range(max_epochs):\n        model.train()\n        train_loss=[]\n        for x_batch, y_batch in training_generator:\n            optimizer.zero_grad()\n            # Forward pass\n            y_pred = model(x_batch)\n            # Compute Loss\n            loss = criterion(y_pred.squeeze(), y_batch)\n            # Backward pass\n            loss.backward()\n            optimizer.step()   \n            train_loss.append(loss.item())\n        \n        #showing last training loss after each epoch\n        all_train_losses.append(np.mean(train_loss))\n        if verbose:\n            print('')\n            print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n        #evaluating the model on the test set after each epoch    \n        valid_loss = evaluate_model(model,valid_generator,criterion)\n        all_valid_losses.append(valid_loss)\n        if verbose:\n            print('valid loss: {}'.format(valid_loss))\n        if apply_early_stopping:\n            if not early_stopping.continue_training(valid_loss):\n                if verbose:\n                    print(\"Early stopping\")\n                break\n        \n    training_execution_time=time.time()-start_time\n    return model,training_execution_time,all_train_losses,all_valid_losses\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:23.833004Z","iopub.execute_input":"2023-02-11T13:12:23.833448Z","iopub.status.idle":"2023-02-11T13:12:23.848004Z","shell.execute_reply.started":"2023-02-11T13:12:23.833413Z","shell.execute_reply":"2023-02-11T13:12:23.846395Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    \n    def __init__(self, patience=4, verbose=False):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = np.Inf\n    \n    def continue_training(self,current_score):\n        if self.best_score > current_score:\n            self.best_score = current_score\n            self.counter = 0\n            if self.verbose:\n                print(\"New best score:\", current_score)\n        else:\n            self.counter+=1\n            if self.verbose:\n                print(self.counter, \" iterations since best score.\")\n                \n        return self.counter <= self.patience \n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:25.082362Z","iopub.execute_input":"2023-02-11T13:12:25.082779Z","iopub.status.idle":"2023-02-11T13:12:25.092771Z","shell.execute_reply.started":"2023-02-11T13:12:25.082745Z","shell.execute_reply":"2023-02-11T13:12:25.091151Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model,generator,criterion):\n    model.eval()\n    batch_losses = []\n    for x_batch, y_batch in generator:\n        # Forward pass\n        y_pred = model(x_batch)\n        # Compute Loss\n        loss = criterion(y_pred.squeeze(), y_batch)\n        batch_losses.append(loss.item())\n    mean_loss = np.mean(batch_losses)    \n    return mean_loss","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:26.174468Z","iopub.execute_input":"2023-02-11T13:12:26.175333Z","iopub.status.idle":"2023-02-11T13:12:26.183526Z","shell.execute_reply.started":"2023-02-11T13:12:26.175277Z","shell.execute_reply":"2023-02-11T13:12:26.181943Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder(len(input_features), 200,12).to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:28.465904Z","iopub.execute_input":"2023-02-11T13:12:28.466714Z","iopub.status.idle":"2023-02-11T13:12:28.477043Z","shell.execute_reply.started":"2023-02-11T13:12:28.466660Z","shell.execute_reply":"2023-02-11T13:12:28.475587Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"markdown","source":"#### Let's start out training, we set our max epochs to 200, and patience to 1 to stop optimization with early stopping using validation data","metadata":{}},{"cell_type":"code","source":"model,training_execution_time,train_losses,valid_losses = training_loop(model,\n                                                                        training_generator,\n                                                                        valid_generator,\n                                                                        optimizer,\n                                                                        criterion,\n                                                                        max_epochs=200,\n                                                                        patience=1,\n                                                                        verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:12:33.104347Z","iopub.execute_input":"2023-02-11T13:12:33.104832Z","iopub.status.idle":"2023-02-11T13:28:08.382226Z","shell.execute_reply.started":"2023-02-11T13:12:33.104772Z","shell.execute_reply":"2023-02-11T13:28:08.380792Z"},"trusted":true},"execution_count":178,"outputs":[{"name":"stdout","text":"\nEpoch 0: train loss: 0.03401328959178411\nvalid loss: 0.0008575627067988737\nNew best score: 0.0008575627067988737\n\nEpoch 1: train loss: 0.00045932396342689635\nvalid loss: 0.0001560099980369813\nNew best score: 0.0001560099980369813\n\nEpoch 2: train loss: 0.00013935975172911624\nvalid loss: 3.8717436811905794e-05\nNew best score: 3.8717436811905794e-05\n\nEpoch 3: train loss: 8.777027623722631e-05\nvalid loss: 1.420720746735616e-05\nNew best score: 1.420720746735616e-05\n\nEpoch 4: train loss: 4.7720780716988864e-05\nvalid loss: 8.61651375510294e-05\n1  iterations since best score.\n\nEpoch 5: train loss: 4.503266017964341e-05\nvalid loss: 5.232725792191601e-06\nNew best score: 5.232725792191601e-06\n\nEpoch 6: train loss: 4.83975129707015e-05\nvalid loss: 4.047768751283106e-06\nNew best score: 4.047768751283106e-06\n\nEpoch 7: train loss: 3.755724020006684e-05\nvalid loss: 4.486010807356494e-06\n1  iterations since best score.\n\nEpoch 8: train loss: 0.00012961280025080733\nvalid loss: 2.307089901065077e-06\nNew best score: 2.307089901065077e-06\n\nEpoch 9: train loss: 3.455623658513493e-05\nvalid loss: 4.292113286807054e-06\n1  iterations since best score.\n\nEpoch 10: train loss: 5.24072451233151e-05\nvalid loss: 0.00018212676819767223\n2  iterations since best score.\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"losses = per_sample_mse(model, valid_generator)\nprint(np.mean(losses))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:28:30.303540Z","iopub.execute_input":"2023-02-11T13:28:30.304574Z","iopub.status.idle":"2023-02-11T13:28:35.636974Z","shell.execute_reply.started":"2023-02-11T13:28:30.304515Z","shell.execute_reply":"2023-02-11T13:28:35.635613Z"},"trusted":true},"execution_count":183,"outputs":[{"name":"stdout","text":"0.000182184\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train_torch[0])\nprint(model(X_train_torch[0].to(DEVICE)))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:31.653291Z","iopub.execute_input":"2023-02-11T13:32:31.654449Z","iopub.status.idle":"2023-02-11T13:32:31.667136Z","shell.execute_reply.started":"2023-02-11T13:32:31.654376Z","shell.execute_reply":"2023-02-11T13:32:31.665501Z"},"trusted":true},"execution_count":193,"outputs":[{"name":"stdout","text":"tensor([-0.0580, -0.2947, -0.9100,  0.3662,  0.5107, -0.2778, -1.7565,  0.8776,\n         0.0288,  0.3861, -0.0321, -0.9196])\ntensor([-0.0595, -0.2905, -0.9045,  0.3668,  0.5084, -0.2832, -1.7517,  0.8791,\n         0.0308,  0.3974, -0.0345, -0.9281], device='cuda:0',\n       grad_fn=<AddBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"genuine_losses = np.array(losses)[y_val_torch.cpu().numpy() == 0]\nfraud_losses = np.array(losses)[y_val_torch.cpu().numpy() == 1]\nprint(\"Average fraud reconstruction error:\", np.mean(fraud_losses))\nprint(\"Average genuine reconstruction error:\", np.mean(genuine_losses))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:33.002687Z","iopub.execute_input":"2023-02-11T13:32:33.003133Z","iopub.status.idle":"2023-02-11T13:32:33.031312Z","shell.execute_reply.started":"2023-02-11T13:32:33.003095Z","shell.execute_reply":"2023-02-11T13:32:33.029318Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stdout","text":"Average fraud reconstruction error: 0.0005219125\nAverage genuine reconstruction error: 0.00018020491\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### After comparing the reconstructed error between fraud and genuine transactions, it appears that fraud are less well reconstructed than genuine transactions","metadata":{}},{"cell_type":"code","source":"predictions_df_AE=df_val\npredictions_df_AE['predictions_loss']=losses","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:37.370390Z","iopub.execute_input":"2023-02-11T13:32:37.371448Z","iopub.status.idle":"2023-02-11T13:32:37.406807Z","shell.execute_reply.started":"2023-02-11T13:32:37.371406Z","shell.execute_reply":"2023-02-11T13:32:37.405607Z"},"trusted":true},"execution_count":195,"outputs":[]},{"cell_type":"code","source":"threshold_AE = np.percentile(predictions_df['predictions_loss'],95)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:40.234344Z","iopub.execute_input":"2023-02-11T13:32:40.235374Z","iopub.status.idle":"2023-02-11T13:32:40.244817Z","shell.execute_reply.started":"2023-02-11T13:32:40.235331Z","shell.execute_reply":"2023-02-11T13:32:40.243218Z"},"trusted":true},"execution_count":196,"outputs":[]},{"cell_type":"code","source":"predictions_df_AE['predictions'] = [1 if x > threshold_AE else 0 for x in predictions_df_AE['predictions_loss']]\npredictions_df_AE","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:44.088819Z","iopub.execute_input":"2023-02-11T13:32:44.089236Z","iopub.status.idle":"2023-02-11T13:32:44.188008Z","shell.execute_reply.started":"2023-02-11T13:32:44.089202Z","shell.execute_reply":"2023-02-11T13:32:44.186599Z"},"trusted":true},"execution_count":197,"outputs":[{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n295133          -0.568910  0.216224       -0.909987     -0.337550   \n309036           0.197485 -0.231450        1.098917      1.251784   \n877558          -1.590770  0.604477       -0.909987      1.429666   \n696676          -0.313445 -0.098344       -0.909987      0.215430   \n351866          -1.079840 -0.087470        1.098917      1.688754   \n...                   ...       ...             ...           ...   \n1115045         -1.590770  0.142411       -0.909987      1.124173   \n81445           -0.057980  0.372293       -0.909987      0.996563   \n1105080         -0.568910  0.283193        1.098917      0.192228   \n838805           0.452949 -0.405876       -0.909987     -1.478312   \n1155691          1.219344  0.181556        1.098917     -0.399422   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n295133        0.929411 -0.248573    -1.206866  1.395357 -0.851290  1.065584   \n309036       -1.164268 -0.264084     1.555412  0.244683  1.348840  1.518580   \n877558        1.138779  0.183478     1.291318 -0.618322  1.202164  0.612587   \n696676        1.138779 -0.285640     0.634652  0.187150  0.615463  0.952334   \n351866        1.557515 -0.275749    -0.457411 -0.388187 -0.411264 -0.180158   \n...                ...       ...          ...       ...       ...       ...   \n1115045      -0.466375 -0.292969    -0.007738 -0.158052  0.908814 -0.859653   \n81445         1.138779 -0.233963    -0.086252 -0.963524  1.495515  0.159590   \n1105080      -0.187218 -0.290813     1.583962 -0.042985 -1.291316 -1.199400   \n838805        0.999200 -0.267485    -0.136216  1.913160 -0.704615 -0.293407   \n1155691      -1.583003 -0.293599    -0.814294  0.014549 -0.997965  1.292082   \n\n              day     month  is_fraud  predictions_loss  predictions  \n295133   0.877664 -0.334296         0          0.000021            0  \n309036  -0.486978 -0.334296         0          0.000092            0  \n877558   0.877664  1.714365         0          0.000090            0  \n696676  -0.032098  1.129033         0          0.000067            0  \n351866   0.422783 -0.041631         0          0.000040            0  \n...           ...       ...       ...               ...          ...  \n1115045 -0.486978 -0.626962         0          0.000099            0  \n81445    1.332544 -1.212294         0          0.000026            0  \n1105080  1.332544 -0.626962         0          0.000031            0  \n838805   0.422783  1.714365         0          0.000024            0  \n1155691 -1.396740 -0.626962         0          0.000153            0  \n\n[129668 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions_loss</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295133</th>\n      <td>-0.568910</td>\n      <td>0.216224</td>\n      <td>-0.909987</td>\n      <td>-0.337550</td>\n      <td>0.929411</td>\n      <td>-0.248573</td>\n      <td>-1.206866</td>\n      <td>1.395357</td>\n      <td>-0.851290</td>\n      <td>1.065584</td>\n      <td>0.877664</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.000021</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>309036</th>\n      <td>0.197485</td>\n      <td>-0.231450</td>\n      <td>1.098917</td>\n      <td>1.251784</td>\n      <td>-1.164268</td>\n      <td>-0.264084</td>\n      <td>1.555412</td>\n      <td>0.244683</td>\n      <td>1.348840</td>\n      <td>1.518580</td>\n      <td>-0.486978</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.000092</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>877558</th>\n      <td>-1.590770</td>\n      <td>0.604477</td>\n      <td>-0.909987</td>\n      <td>1.429666</td>\n      <td>1.138779</td>\n      <td>0.183478</td>\n      <td>1.291318</td>\n      <td>-0.618322</td>\n      <td>1.202164</td>\n      <td>0.612587</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.000090</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>696676</th>\n      <td>-0.313445</td>\n      <td>-0.098344</td>\n      <td>-0.909987</td>\n      <td>0.215430</td>\n      <td>1.138779</td>\n      <td>-0.285640</td>\n      <td>0.634652</td>\n      <td>0.187150</td>\n      <td>0.615463</td>\n      <td>0.952334</td>\n      <td>-0.032098</td>\n      <td>1.129033</td>\n      <td>0</td>\n      <td>0.000067</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>351866</th>\n      <td>-1.079840</td>\n      <td>-0.087470</td>\n      <td>1.098917</td>\n      <td>1.688754</td>\n      <td>1.557515</td>\n      <td>-0.275749</td>\n      <td>-0.457411</td>\n      <td>-0.388187</td>\n      <td>-0.411264</td>\n      <td>-0.180158</td>\n      <td>0.422783</td>\n      <td>-0.041631</td>\n      <td>0</td>\n      <td>0.000040</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1115045</th>\n      <td>-1.590770</td>\n      <td>0.142411</td>\n      <td>-0.909987</td>\n      <td>1.124173</td>\n      <td>-0.466375</td>\n      <td>-0.292969</td>\n      <td>-0.007738</td>\n      <td>-0.158052</td>\n      <td>0.908814</td>\n      <td>-0.859653</td>\n      <td>-0.486978</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000099</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81445</th>\n      <td>-0.057980</td>\n      <td>0.372293</td>\n      <td>-0.909987</td>\n      <td>0.996563</td>\n      <td>1.138779</td>\n      <td>-0.233963</td>\n      <td>-0.086252</td>\n      <td>-0.963524</td>\n      <td>1.495515</td>\n      <td>0.159590</td>\n      <td>1.332544</td>\n      <td>-1.212294</td>\n      <td>0</td>\n      <td>0.000026</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1105080</th>\n      <td>-0.568910</td>\n      <td>0.283193</td>\n      <td>1.098917</td>\n      <td>0.192228</td>\n      <td>-0.187218</td>\n      <td>-0.290813</td>\n      <td>1.583962</td>\n      <td>-0.042985</td>\n      <td>-1.291316</td>\n      <td>-1.199400</td>\n      <td>1.332544</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000031</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>838805</th>\n      <td>0.452949</td>\n      <td>-0.405876</td>\n      <td>-0.909987</td>\n      <td>-1.478312</td>\n      <td>0.999200</td>\n      <td>-0.267485</td>\n      <td>-0.136216</td>\n      <td>1.913160</td>\n      <td>-0.704615</td>\n      <td>-0.293407</td>\n      <td>0.422783</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.000024</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1155691</th>\n      <td>1.219344</td>\n      <td>0.181556</td>\n      <td>1.098917</td>\n      <td>-0.399422</td>\n      <td>-1.583003</td>\n      <td>-0.293599</td>\n      <td>-0.814294</td>\n      <td>0.014549</td>\n      <td>-0.997965</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000153</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>129668 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import metrics\ndef performance_assessment(predictions_df, output_feature='is_fraud', \n                           prediction_feature='predictions', rounded=True):\n    \n    AUC_ROC = metrics.roc_auc_score(predictions_df[output_feature], predictions_df[prediction_feature])\n    AP = metrics.average_precision_score(predictions_df[output_feature], predictions_df[prediction_feature])\n    \n    performances = pd.DataFrame([[AUC_ROC, AP]], \n                           columns=['AUC ROC','Average precision'])\n    performances = performances.round(3)\n    \n    return performances","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:49.705982Z","iopub.execute_input":"2023-02-11T13:32:49.706401Z","iopub.status.idle":"2023-02-11T13:32:49.716491Z","shell.execute_reply.started":"2023-02-11T13:32:49.706367Z","shell.execute_reply":"2023-02-11T13:32:49.714778Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"performance_assessment(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:32:51.352370Z","iopub.execute_input":"2023-02-11T13:32:51.353528Z","iopub.status.idle":"2023-02-11T13:32:51.405018Z","shell.execute_reply.started":"2023-02-11T13:32:51.353458Z","shell.execute_reply":"2023-02-11T13:32:51.403477Z"},"trusted":true},"execution_count":200,"outputs":[{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"   AUC ROC  Average precision\n0    0.749              0.037","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AUC ROC</th>\n      <th>Average precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.749</td>\n      <td>0.037</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Isolation Forest VS AutoEncoder","metadata":{"execution":{"iopub.status.busy":"2023-01-01T14:09:41.476457Z","iopub.execute_input":"2023-01-01T14:09:41.476835Z","iopub.status.idle":"2023-01-01T14:09:41.488625Z","shell.execute_reply.started":"2023-01-01T14:09:41.476802Z","shell.execute_reply":"2023-01-01T14:09:41.487318Z"}}},{"cell_type":"markdown","source":"#### Isolation forests are an ensemble machine learning algorithm used for anomaly detection. They work by randomly partitioning the feature space and then making a decision tree. Points that are easier to isolate (i.e., require fewer splits) are considered to be anomalies. This approach is effective when the anomalies are well separated from the normal data points, and the anomalies are more scattered throughout the feature space.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\nanomalyclassifier = IsolationForest(random_state=SEED, n_estimators=40)\nanomalyclassifier.fit(df_train[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:01:47.687733Z","iopub.execute_input":"2023-02-11T13:01:47.688188Z","iopub.status.idle":"2023-02-11T13:01:51.132466Z","shell.execute_reply.started":"2023-02-11T13:01:47.688153Z","shell.execute_reply":"2023-02-11T13:01:51.131164Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"IsolationForest(n_estimators=40, random_state=42)"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df_IF = df_val\npredictions_df_IF['predictions_prob'] = -anomalyclassifier.score_samples(df_val[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:05:33.159012Z","iopub.execute_input":"2023-02-11T13:05:33.160197Z","iopub.status.idle":"2023-02-11T13:05:34.958225Z","shell.execute_reply.started":"2023-02-11T13:05:33.160132Z","shell.execute_reply":"2023-02-11T13:05:34.956888Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"threshold = np.percentile(predictions_df_IF['predictions_prob'],95)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:11:03.202678Z","iopub.execute_input":"2023-02-11T13:11:03.203112Z","iopub.status.idle":"2023-02-11T13:11:03.213330Z","shell.execute_reply.started":"2023-02-11T13:11:03.203078Z","shell.execute_reply":"2023-02-11T13:11:03.211698Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"predictions_df_IF['predictions'] = [1 if x > threshold else 0 for x in predictions_df_IF['predictions_prob']]\npredictions_df_IF","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:11:08.221607Z","iopub.execute_input":"2023-02-11T13:11:08.222570Z","iopub.status.idle":"2023-02-11T13:11:08.325568Z","shell.execute_reply.started":"2023-02-11T13:11:08.222526Z","shell.execute_reply":"2023-02-11T13:11:08.323877Z"},"trusted":true},"execution_count":165,"outputs":[{"execution_count":165,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n295133          -0.568910  0.216224       -0.909987     -0.337550   \n309036           0.197485 -0.231450        1.098917      1.251784   \n877558          -1.590770  0.604477       -0.909987      1.429666   \n696676          -0.313445 -0.098344       -0.909987      0.215430   \n351866          -1.079840 -0.087470        1.098917      1.688754   \n...                   ...       ...             ...           ...   \n1115045         -1.590770  0.142411       -0.909987      1.124173   \n81445           -0.057980  0.372293       -0.909987      0.996563   \n1105080         -0.568910  0.283193        1.098917      0.192228   \n838805           0.452949 -0.405876       -0.909987     -1.478312   \n1155691          1.219344  0.181556        1.098917     -0.399422   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n295133        0.929411 -0.248573    -1.206866  1.395357 -0.851290  1.065584   \n309036       -1.164268 -0.264084     1.555412  0.244683  1.348840  1.518580   \n877558        1.138779  0.183478     1.291318 -0.618322  1.202164  0.612587   \n696676        1.138779 -0.285640     0.634652  0.187150  0.615463  0.952334   \n351866        1.557515 -0.275749    -0.457411 -0.388187 -0.411264 -0.180158   \n...                ...       ...          ...       ...       ...       ...   \n1115045      -0.466375 -0.292969    -0.007738 -0.158052  0.908814 -0.859653   \n81445         1.138779 -0.233963    -0.086252 -0.963524  1.495515  0.159590   \n1105080      -0.187218 -0.290813     1.583962 -0.042985 -1.291316 -1.199400   \n838805        0.999200 -0.267485    -0.136216  1.913160 -0.704615 -0.293407   \n1155691      -1.583003 -0.293599    -0.814294  0.014549 -0.997965  1.292082   \n\n              day     month  is_fraud  predictions_prob  predictions  \n295133   0.877664 -0.334296         0          0.479600            0  \n309036  -0.486978 -0.334296         0          0.533265            0  \n877558   0.877664  1.714365         0          0.570037            1  \n696676  -0.032098  1.129033         0          0.472817            0  \n351866   0.422783 -0.041631         0          0.473646            0  \n...           ...       ...       ...               ...          ...  \n1115045 -0.486978 -0.626962         0          0.467666            0  \n81445    1.332544 -1.212294         0          0.521957            0  \n1105080  1.332544 -0.626962         0          0.484813            0  \n838805   0.422783  1.714365         0          0.490951            0  \n1155691 -1.396740 -0.626962         0          0.489703            0  \n\n[129668 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions_prob</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295133</th>\n      <td>-0.568910</td>\n      <td>0.216224</td>\n      <td>-0.909987</td>\n      <td>-0.337550</td>\n      <td>0.929411</td>\n      <td>-0.248573</td>\n      <td>-1.206866</td>\n      <td>1.395357</td>\n      <td>-0.851290</td>\n      <td>1.065584</td>\n      <td>0.877664</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.479600</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>309036</th>\n      <td>0.197485</td>\n      <td>-0.231450</td>\n      <td>1.098917</td>\n      <td>1.251784</td>\n      <td>-1.164268</td>\n      <td>-0.264084</td>\n      <td>1.555412</td>\n      <td>0.244683</td>\n      <td>1.348840</td>\n      <td>1.518580</td>\n      <td>-0.486978</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.533265</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>877558</th>\n      <td>-1.590770</td>\n      <td>0.604477</td>\n      <td>-0.909987</td>\n      <td>1.429666</td>\n      <td>1.138779</td>\n      <td>0.183478</td>\n      <td>1.291318</td>\n      <td>-0.618322</td>\n      <td>1.202164</td>\n      <td>0.612587</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.570037</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>696676</th>\n      <td>-0.313445</td>\n      <td>-0.098344</td>\n      <td>-0.909987</td>\n      <td>0.215430</td>\n      <td>1.138779</td>\n      <td>-0.285640</td>\n      <td>0.634652</td>\n      <td>0.187150</td>\n      <td>0.615463</td>\n      <td>0.952334</td>\n      <td>-0.032098</td>\n      <td>1.129033</td>\n      <td>0</td>\n      <td>0.472817</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>351866</th>\n      <td>-1.079840</td>\n      <td>-0.087470</td>\n      <td>1.098917</td>\n      <td>1.688754</td>\n      <td>1.557515</td>\n      <td>-0.275749</td>\n      <td>-0.457411</td>\n      <td>-0.388187</td>\n      <td>-0.411264</td>\n      <td>-0.180158</td>\n      <td>0.422783</td>\n      <td>-0.041631</td>\n      <td>0</td>\n      <td>0.473646</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1115045</th>\n      <td>-1.590770</td>\n      <td>0.142411</td>\n      <td>-0.909987</td>\n      <td>1.124173</td>\n      <td>-0.466375</td>\n      <td>-0.292969</td>\n      <td>-0.007738</td>\n      <td>-0.158052</td>\n      <td>0.908814</td>\n      <td>-0.859653</td>\n      <td>-0.486978</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.467666</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81445</th>\n      <td>-0.057980</td>\n      <td>0.372293</td>\n      <td>-0.909987</td>\n      <td>0.996563</td>\n      <td>1.138779</td>\n      <td>-0.233963</td>\n      <td>-0.086252</td>\n      <td>-0.963524</td>\n      <td>1.495515</td>\n      <td>0.159590</td>\n      <td>1.332544</td>\n      <td>-1.212294</td>\n      <td>0</td>\n      <td>0.521957</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1105080</th>\n      <td>-0.568910</td>\n      <td>0.283193</td>\n      <td>1.098917</td>\n      <td>0.192228</td>\n      <td>-0.187218</td>\n      <td>-0.290813</td>\n      <td>1.583962</td>\n      <td>-0.042985</td>\n      <td>-1.291316</td>\n      <td>-1.199400</td>\n      <td>1.332544</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.484813</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>838805</th>\n      <td>0.452949</td>\n      <td>-0.405876</td>\n      <td>-0.909987</td>\n      <td>-1.478312</td>\n      <td>0.999200</td>\n      <td>-0.267485</td>\n      <td>-0.136216</td>\n      <td>1.913160</td>\n      <td>-0.704615</td>\n      <td>-0.293407</td>\n      <td>0.422783</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.490951</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1155691</th>\n      <td>1.219344</td>\n      <td>0.181556</td>\n      <td>1.098917</td>\n      <td>-0.399422</td>\n      <td>-1.583003</td>\n      <td>-0.293599</td>\n      <td>-0.814294</td>\n      <td>0.014549</td>\n      <td>-0.997965</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.489703</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>129668 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performance_assessment(predictions_df_IF)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T13:11:17.658748Z","iopub.execute_input":"2023-02-11T13:11:17.659170Z","iopub.status.idle":"2023-02-11T13:11:17.712040Z","shell.execute_reply.started":"2023-02-11T13:11:17.659136Z","shell.execute_reply":"2023-02-11T13:11:17.710442Z"},"trusted":true},"execution_count":166,"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"   AUC ROC  Average precision\n0    0.713              0.029","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AUC ROC</th>\n      <th>Average precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.713</td>\n      <td>0.029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"### Both autoencoders and isolation forests have their strengths and weaknesses, and the best choice for a particular problem will depend on the characteristics of the data and the specific requirements of the problem. In some cases, a combination of both techniques might produce the best results.\n\n### In conclusion, for the problem at hand, AutoEncoder was able to detect fraud more accuractly than our Isolation Forest (AUC_ROC Score of 0.75 vs 0.71)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}