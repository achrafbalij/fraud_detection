{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\nimport torch\nfrom sklearn.model_selection import train_test_split\n\npd.set_option('display.max_columns', None)\nsns.set(rc = {'figure.figsize':(15,8)})\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-11T17:42:48.038273Z","iopub.execute_input":"2023-02-11T17:42:48.038667Z","iopub.status.idle":"2023-02-11T17:42:50.134604Z","shell.execute_reply.started":"2023-02-11T17:42:48.038635Z","shell.execute_reply":"2023-02-11T17:42:50.133502Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/fraud-detection/fraudTest.csv\n/kaggle/input/fraud-detection/fraudTrain.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"SEED = 42\n\nif torch.cuda.is_available():\n    DEVICE = \"cuda\" \nelse:\n    DEVICE = \"cpu\"\nprint(\"Selected device is\",DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:42:50.136721Z","iopub.execute_input":"2023-02-11T17:42:50.137973Z","iopub.status.idle":"2023-02-11T17:42:50.209554Z","shell.execute_reply.started":"2023-02-11T17:42:50.137933Z","shell.execute_reply":"2023-02-11T17:42:50.208490Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Selected device is cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Loading and preprocessing the data ","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/fraud-detection/fraudTrain.csv')\ndf.drop_duplicates(inplace=True)\ndf = df.drop('Unnamed: 0', axis=1)\ndf['age']=dt.date.today().year-pd.to_datetime(df['dob']).dt.year\ndf['hour']=pd.to_datetime(df['trans_date_trans_time']).dt.hour\ndf['daily']=pd.to_datetime(df['trans_date_trans_time']).dt.day\ndf['day']=pd.to_datetime(df['trans_date_trans_time']).dt.dayofweek\ndf['month']=pd.to_datetime(df['trans_date_trans_time']).dt.month","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:42:50.212026Z","iopub.execute_input":"2023-02-11T17:42:50.212788Z","iopub.status.idle":"2023-02-11T17:43:06.246334Z","shell.execute_reply.started":"2023-02-11T17:42:50.212746Z","shell.execute_reply":"2023-02-11T17:43:06.245215Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ndf['category_encoded'] = labelencoder.fit_transform(df['category'])\ndf['gender_encoded'] = labelencoder.fit_transform(df['gender'])\ndf['city_encoded'] = labelencoder.fit_transform(df['city'])\ndf['state_encoded'] =labelencoder.fit_transform(df['state'])\ndf['job_encoded'] = labelencoder.fit_transform(df['job'])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:06.248707Z","iopub.execute_input":"2023-02-11T17:43:06.249095Z","iopub.status.idle":"2023-02-11T17:43:07.597942Z","shell.execute_reply.started":"2023-02-11T17:43:06.249048Z","shell.execute_reply":"2023-02-11T17:43:07.596782Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X = df[['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month', 'is_fraud']]\ninput_features = ['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month']","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:07.599366Z","iopub.execute_input":"2023-02-11T17:43:07.600103Z","iopub.status.idle":"2023-02-11T17:43:07.742493Z","shell.execute_reply.started":"2023-02-11T17:43:07.600062Z","shell.execute_reply":"2023-02-11T17:43:07.741480Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### Spliting the training set into training (90%) and validation(10%) set","metadata":{}},{"cell_type":"code","source":"df_train, df_val = train_test_split(X, test_size=0.1, random_state=42, stratify=X['is_fraud'])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:23.940828Z","iopub.execute_input":"2023-02-11T17:56:23.941204Z","iopub.status.idle":"2023-02-11T17:56:24.451919Z","shell.execute_reply.started":"2023-02-11T17:56:23.941170Z","shell.execute_reply":"2023-02-11T17:56:24.450888Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### We scale the data","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\nscaler = preprocessing.StandardScaler()\nscaler.fit(df_train[input_features])\n\ndf_train[input_features]=scaler.transform(df_train[input_features])\ndf_val[input_features]=scaler.transform(df_val[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:27.773166Z","iopub.execute_input":"2023-02-11T17:56:27.774183Z","iopub.status.idle":"2023-02-11T17:56:28.360592Z","shell.execute_reply.started":"2023-02-11T17:56:27.774139Z","shell.execute_reply":"2023-02-11T17:56:28.359607Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.iloc[:,:-1]\ny_train = df_train.iloc[:,-1]\nX_val = df_val.iloc[:,:-1]\ny_val = df_val.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:29.760006Z","iopub.execute_input":"2023-02-11T17:56:29.760399Z","iopub.status.idle":"2023-02-11T17:56:29.843323Z","shell.execute_reply.started":"2023-02-11T17:56:29.760366Z","shell.execute_reply":"2023-02-11T17:56:29.842351Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### We convert our features and labels into torch tensors","metadata":{}},{"cell_type":"code","source":"X_train_torch = torch.FloatTensor(X_train.values)\nX_val_torch = torch.FloatTensor(X_val.values)\ny_train_torch = torch.FloatTensor(y_train.values)\ny_val_torch = torch.FloatTensor(y_val.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:31.125778Z","iopub.execute_input":"2023-02-11T17:56:31.126140Z","iopub.status.idle":"2023-02-11T17:56:31.223181Z","shell.execute_reply.started":"2023-02-11T17:56:31.126109Z","shell.execute_reply":"2023-02-11T17:56:31.222162Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"#### As we all know that in case of fraud detection, companies do not always have a labeled historical data. So for this reason why we tried to rely on unsupervised learning models. We will also rely on a new dataset which receives the descriptive features of a transaction and returns it as both input and output","metadata":{}},{"cell_type":"code","source":"class FraudDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, x,output=True):\n        'Initialization'\n        self.x = x\n        self.output = output\n\n    def __len__(self):\n        'Returns the total number of samples'\n        return len(self.x)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        item = self.x[index].to(DEVICE)\n        if self.output:\n            return item, item\n        else:\n            return item","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.406734Z","iopub.execute_input":"2023-02-11T17:43:09.407509Z","iopub.status.idle":"2023-02-11T17:43:09.415199Z","shell.execute_reply.started":"2023-02-11T17:43:09.407465Z","shell.execute_reply":"2023-02-11T17:43:09.414236Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_set = FraudDataset(X_train_torch)\nval_set = FraudDataset(X_val_torch)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.417053Z","iopub.execute_input":"2023-02-11T17:43:09.417939Z","iopub.status.idle":"2023-02-11T17:43:09.427713Z","shell.execute_reply.started":"2023-02-11T17:43:09.417897Z","shell.execute_reply":"2023-02-11T17:43:09.426553Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_loader_params = {'batch_size': 64,\n              'shuffle': True,\n              'num_workers': 0}\nvalid_loader_params = {'batch_size': 64,\n              'num_workers': 0}\n    \ntraining_generator = torch.utils.data.DataLoader(train_set, **train_loader_params)\nvalid_generator = torch.utils.data.DataLoader(val_set, **valid_loader_params)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.436729Z","iopub.execute_input":"2023-02-11T17:43:09.437144Z","iopub.status.idle":"2023-02-11T17:43:09.447627Z","shell.execute_reply.started":"2023-02-11T17:43:09.437107Z","shell.execute_reply":"2023-02-11T17:43:09.446463Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### We resorted to a regular feed-forward autoencoder with the following architecture:\n* A first input layer with ReLu activation (input_size, intermediate_size)\n\n* A second layer with ReLu activation (intermediate_size, code_size)\n\n* A third layer with ReLu activation (code_size, intermediate_size)\n\n* An output layer with linear activation (intermediate_size, input_size)","metadata":{}},{"cell_type":"code","source":"class Autoencoder(torch.nn.Module):\n    \n        def __init__(self, input_size, intermediate_size, code_size):\n            super(Autoencoder, self).__init__()\n            # parameters\n            self.input_size = input_size\n            self.intermediate_size = intermediate_size           \n            self.code_size  = code_size\n            \n            self.relu = torch.nn.ReLU()   \n            \n            #encoder\n            self.fc1 = torch.nn.Linear(self.input_size, self.intermediate_size)\n            self.fc2 = torch.nn.Linear(self.intermediate_size, self.code_size)\n            \n            #decoder \n            self.fc3 = torch.nn.Linear(self.code_size, self.intermediate_size)            \n            self.fc4 = torch.nn.Linear(self.intermediate_size, self.input_size)\n            \n\n            \n            \n        def forward(self, x):\n            \n            hidden = self.fc1(x)\n            hidden = self.relu(hidden)\n            \n            code = self.fc2(hidden)\n            code = self.relu(code)\n \n            hidden = self.fc3(code)\n            hidden = self.relu(hidden)\n            \n            output = self.fc4(hidden)\n            \n            return output","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.452496Z","iopub.execute_input":"2023-02-11T17:43:09.452835Z","iopub.status.idle":"2023-02-11T17:43:09.465204Z","shell.execute_reply.started":"2023-02-11T17:43:09.452803Z","shell.execute_reply":"2023-02-11T17:43:09.464235Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.MSELoss().to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.470254Z","iopub.execute_input":"2023-02-11T17:43:09.473481Z","iopub.status.idle":"2023-02-11T17:43:09.480054Z","shell.execute_reply.started":"2023-02-11T17:43:09.473446Z","shell.execute_reply":"2023-02-11T17:43:09.479041Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Our goal is to predict the input from the input. Therefore, one cannot directly use its prediction for fraud detection. Instead, the idea is to use its reconstruction error between the input and the output.\n\n#### the reconstruction error can be considered as predicted fraud score, and therfore the higher the error, the higher the risk.","metadata":{}},{"cell_type":"code","source":"def per_sample_mse(model, generator):\n    \n    model.eval()\n    criterion = torch.nn.MSELoss(reduction=\"none\")\n    batch_losses = []\n    \n    for x_batch, y_batch in generator:\n        # Forward pass\n        y_pred = model(x_batch)\n        # Compute Loss\n        loss = criterion(y_pred.squeeze(), y_batch)\n        loss_app = list(torch.mean(loss,axis=1).detach().cpu().numpy())\n        batch_losses.extend(loss_app)\n    \n    return batch_losses","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.484248Z","iopub.execute_input":"2023-02-11T17:43:09.485954Z","iopub.status.idle":"2023-02-11T17:43:09.496212Z","shell.execute_reply.started":"2023-02-11T17:43:09.485918Z","shell.execute_reply":"2023-02-11T17:43:09.495350Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import time\ndef training_loop(model,training_generator,valid_generator,optimizer,criterion,max_epochs=100,apply_early_stopping=True,patience=4,verbose=False):\n    #Setting the model in training mode\n    model.train()\n\n    if apply_early_stopping:\n        early_stopping = EarlyStopping(verbose=verbose,patience=patience)\n    \n    all_train_losses = []\n    all_valid_losses = []\n    \n    #Training loop\n    start_time=time.time()\n    for epoch in range(max_epochs):\n        model.train()\n        train_loss=[]\n        for x_batch, y_batch in training_generator:\n            optimizer.zero_grad()\n            # Forward pass\n            y_pred = model(x_batch)\n            # Compute Loss\n            loss = criterion(y_pred.squeeze(), y_batch)\n            # Backward pass\n            loss.backward()\n            optimizer.step()   \n            train_loss.append(loss.item())\n        \n        #showing last training loss after each epoch\n        all_train_losses.append(np.mean(train_loss))\n        if verbose:\n            print('')\n            print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n        #evaluating the model on the test set after each epoch    \n        valid_loss = evaluate_model(model,valid_generator,criterion)\n        all_valid_losses.append(valid_loss)\n        if verbose:\n            print('valid loss: {}'.format(valid_loss))\n        if apply_early_stopping:\n            if not early_stopping.continue_training(valid_loss):\n                if verbose:\n                    print(\"Early stopping\")\n                break\n        \n    training_execution_time=time.time()-start_time\n    return model,training_execution_time,all_train_losses,all_valid_losses\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.500485Z","iopub.execute_input":"2023-02-11T17:43:09.502278Z","iopub.status.idle":"2023-02-11T17:43:09.517650Z","shell.execute_reply.started":"2023-02-11T17:43:09.502244Z","shell.execute_reply":"2023-02-11T17:43:09.516646Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    \n    def __init__(self, patience=4, verbose=False):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = np.Inf\n    \n    def continue_training(self,current_score):\n        if self.best_score > current_score:\n            self.best_score = current_score\n            self.counter = 0\n            if self.verbose:\n                print(\"New best score:\", current_score)\n        else:\n            self.counter+=1\n            if self.verbose:\n                print(self.counter, \" iterations since best score.\")\n                \n        return self.counter <= self.patience \n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.522537Z","iopub.execute_input":"2023-02-11T17:43:09.523073Z","iopub.status.idle":"2023-02-11T17:43:09.534842Z","shell.execute_reply.started":"2023-02-11T17:43:09.523039Z","shell.execute_reply":"2023-02-11T17:43:09.533950Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model,generator,criterion):\n    model.eval()\n    batch_losses = []\n    for x_batch, y_batch in generator:\n        # Forward pass\n        y_pred = model(x_batch)\n        # Compute Loss\n        loss = criterion(y_pred.squeeze(), y_batch)\n        batch_losses.append(loss.item())\n    mean_loss = np.mean(batch_losses)    \n    return mean_loss","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.539765Z","iopub.execute_input":"2023-02-11T17:43:09.540353Z","iopub.status.idle":"2023-02-11T17:43:09.551340Z","shell.execute_reply.started":"2023-02-11T17:43:09.540298Z","shell.execute_reply":"2023-02-11T17:43:09.550433Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder(len(input_features), 200,12).to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:09.556212Z","iopub.execute_input":"2023-02-11T17:43:09.557118Z","iopub.status.idle":"2023-02-11T17:43:12.331471Z","shell.execute_reply.started":"2023-02-11T17:43:09.556921Z","shell.execute_reply":"2023-02-11T17:43:12.330468Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### Let's start out training, we set our max epochs to 200, and patience to 1 to stop optimization with early stopping using validation data","metadata":{}},{"cell_type":"code","source":"model,training_execution_time,train_losses,valid_losses = training_loop(model,\n                                                                        training_generator,\n                                                                        valid_generator,\n                                                                        optimizer,\n                                                                        criterion,\n                                                                        max_epochs=200,\n                                                                        patience=1,\n                                                                        verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:43:12.333049Z","iopub.execute_input":"2023-02-11T17:43:12.333452Z","iopub.status.idle":"2023-02-11T17:53:59.031848Z","shell.execute_reply.started":"2023-02-11T17:43:12.333411Z","shell.execute_reply":"2023-02-11T17:53:59.030655Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\nEpoch 0: train loss: 0.0254839206791644\nvalid loss: 0.0006543407754234687\nNew best score: 0.0006543407754234687\n\nEpoch 1: train loss: 0.0003351948009591777\nvalid loss: 0.00010380902268535175\nNew best score: 0.00010380902268535175\n\nEpoch 2: train loss: 0.0001540026365341019\nvalid loss: 3.535443108111779e-05\nNew best score: 3.535443108111779e-05\n\nEpoch 3: train loss: 9.210503065486007e-05\nvalid loss: 4.0458550084152624e-05\n1  iterations since best score.\n\nEpoch 4: train loss: 0.00013882408549190914\nvalid loss: 1.0726513248016292e-05\nNew best score: 1.0726513248016292e-05\n\nEpoch 5: train loss: 0.00011582699503669064\nvalid loss: 9.615116163826005e-06\nNew best score: 9.615116163826005e-06\n\nEpoch 6: train loss: 3.868816951634304e-05\nvalid loss: 3.977408472586091e-06\nNew best score: 3.977408472586091e-06\n\nEpoch 7: train loss: 2.992825220571023e-05\nvalid loss: 3.5746038169201276e-06\nNew best score: 3.5746038169201276e-06\n\nEpoch 8: train loss: 3.296127446273784e-05\nvalid loss: 2.1220099967374235e-06\nNew best score: 2.1220099967374235e-06\n\nEpoch 9: train loss: 2.579766598829196e-05\nvalid loss: 5.879261604416834e-06\n1  iterations since best score.\n\nEpoch 10: train loss: 3.1819469651135705e-05\nvalid loss: 5.200297571608315e-06\n2  iterations since best score.\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"code","source":"losses = per_sample_mse(model, valid_generator)\nprint(np.mean(losses))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:53:59.033492Z","iopub.execute_input":"2023-02-11T17:53:59.034114Z","iopub.status.idle":"2023-02-11T17:54:02.556347Z","shell.execute_reply.started":"2023-02-11T17:53:59.034071Z","shell.execute_reply":"2023-02-11T17:54:02.555317Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"5.2014793e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train_torch[0])\nprint(model(X_train_torch[0].to(DEVICE)))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:54:02.557927Z","iopub.execute_input":"2023-02-11T17:54:02.558334Z","iopub.status.idle":"2023-02-11T17:54:02.592691Z","shell.execute_reply.started":"2023-02-11T17:54:02.558281Z","shell.execute_reply":"2023-02-11T17:54:02.591527Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"tensor([-0.0580, -0.2947, -0.9100,  0.3662,  0.5107, -0.2778, -1.7565,  0.8776,\n         0.0288,  0.3861, -0.0321, -0.9196])\ntensor([-0.0580, -0.2944, -0.9083,  0.3667,  0.5104, -0.2761, -1.7569,  0.8781,\n         0.0286,  0.3846, -0.0316, -0.9184], device='cuda:0',\n       grad_fn=<AddBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"genuine_losses = np.array(losses)[y_val_torch.cpu().numpy() == 0]\nfraud_losses = np.array(losses)[y_val_torch.cpu().numpy() == 1]\nprint(\"Average fraud reconstruction error:\", np.mean(fraud_losses))\nprint(\"Average genuine reconstruction error:\", np.mean(genuine_losses))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:54:02.594081Z","iopub.execute_input":"2023-02-11T17:54:02.594552Z","iopub.status.idle":"2023-02-11T17:54:02.616346Z","shell.execute_reply.started":"2023-02-11T17:54:02.594516Z","shell.execute_reply":"2023-02-11T17:54:02.615461Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Average fraud reconstruction error: 2.282864e-05\nAverage genuine reconstruction error: 5.098793e-06\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### After comparing the reconstructed error between fraud and genuine transactions, it appears that fraud are less well reconstructed than genuine transactions","metadata":{}},{"cell_type":"code","source":"predictions_df_AE=df_val.copy()\npredictions_df_AE['predictions_loss']=losses","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:42.514892Z","iopub.execute_input":"2023-02-11T17:56:42.516089Z","iopub.status.idle":"2023-02-11T17:56:42.553360Z","shell.execute_reply.started":"2023-02-11T17:56:42.516041Z","shell.execute_reply":"2023-02-11T17:56:42.552370Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"threshold_AE = np.percentile(predictions_df_AE['predictions_loss'],95)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:44.108538Z","iopub.execute_input":"2023-02-11T17:56:44.108907Z","iopub.status.idle":"2023-02-11T17:56:44.115195Z","shell.execute_reply.started":"2023-02-11T17:56:44.108876Z","shell.execute_reply":"2023-02-11T17:56:44.114104Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"predictions_df_AE['predictions'] = [1 if x > threshold_AE else 0 for x in predictions_df_AE['predictions_loss']]\npredictions_df_AE","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:44.460459Z","iopub.execute_input":"2023-02-11T17:56:44.460827Z","iopub.status.idle":"2023-02-11T17:56:44.536280Z","shell.execute_reply.started":"2023-02-11T17:56:44.460795Z","shell.execute_reply":"2023-02-11T17:56:44.535109Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n295133          -0.568910  0.216224       -0.909987     -0.337550   \n309036           0.197485 -0.231450        1.098917      1.251784   \n877558          -1.590770  0.604477       -0.909987      1.429666   \n696676          -0.313445 -0.098344       -0.909987      0.215430   \n351866          -1.079840 -0.087470        1.098917      1.688754   \n...                   ...       ...             ...           ...   \n1115045         -1.590770  0.142411       -0.909987      1.124173   \n81445           -0.057980  0.372293       -0.909987      0.996563   \n1105080         -0.568910  0.283193        1.098917      0.192228   \n838805           0.452949 -0.405876       -0.909987     -1.478312   \n1155691          1.219344  0.181556        1.098917     -0.399422   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n295133        0.929411 -0.248573    -1.206866  1.395357 -0.851290  1.065584   \n309036       -1.164268 -0.264084     1.555412  0.244683  1.348840  1.518580   \n877558        1.138779  0.183478     1.291318 -0.618322  1.202164  0.612587   \n696676        1.138779 -0.285640     0.634652  0.187150  0.615463  0.952334   \n351866        1.557515 -0.275749    -0.457411 -0.388187 -0.411264 -0.180158   \n...                ...       ...          ...       ...       ...       ...   \n1115045      -0.466375 -0.292969    -0.007738 -0.158052  0.908814 -0.859653   \n81445         1.138779 -0.233963    -0.086252 -0.963524  1.495515  0.159590   \n1105080      -0.187218 -0.290813     1.583962 -0.042985 -1.291316 -1.199400   \n838805        0.999200 -0.267485    -0.136216  1.913160 -0.704615 -0.293407   \n1155691      -1.583003 -0.293599    -0.814294  0.014549 -0.997965  1.292082   \n\n              day     month  is_fraud  predictions_loss  predictions  \n295133   0.877664 -0.334296         0          0.000002            0  \n309036  -0.486978 -0.334296         0          0.000003            0  \n877558   0.877664  1.714365         0          0.000005            0  \n696676  -0.032098  1.129033         0          0.000002            0  \n351866   0.422783 -0.041631         0          0.000002            0  \n...           ...       ...       ...               ...          ...  \n1115045 -0.486978 -0.626962         0          0.000002            0  \n81445    1.332544 -1.212294         0          0.000003            0  \n1105080  1.332544 -0.626962         0          0.000002            0  \n838805   0.422783  1.714365         0          0.000002            0  \n1155691 -1.396740 -0.626962         0          0.000003            0  \n\n[129668 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions_loss</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295133</th>\n      <td>-0.568910</td>\n      <td>0.216224</td>\n      <td>-0.909987</td>\n      <td>-0.337550</td>\n      <td>0.929411</td>\n      <td>-0.248573</td>\n      <td>-1.206866</td>\n      <td>1.395357</td>\n      <td>-0.851290</td>\n      <td>1.065584</td>\n      <td>0.877664</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>309036</th>\n      <td>0.197485</td>\n      <td>-0.231450</td>\n      <td>1.098917</td>\n      <td>1.251784</td>\n      <td>-1.164268</td>\n      <td>-0.264084</td>\n      <td>1.555412</td>\n      <td>0.244683</td>\n      <td>1.348840</td>\n      <td>1.518580</td>\n      <td>-0.486978</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.000003</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>877558</th>\n      <td>-1.590770</td>\n      <td>0.604477</td>\n      <td>-0.909987</td>\n      <td>1.429666</td>\n      <td>1.138779</td>\n      <td>0.183478</td>\n      <td>1.291318</td>\n      <td>-0.618322</td>\n      <td>1.202164</td>\n      <td>0.612587</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.000005</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>696676</th>\n      <td>-0.313445</td>\n      <td>-0.098344</td>\n      <td>-0.909987</td>\n      <td>0.215430</td>\n      <td>1.138779</td>\n      <td>-0.285640</td>\n      <td>0.634652</td>\n      <td>0.187150</td>\n      <td>0.615463</td>\n      <td>0.952334</td>\n      <td>-0.032098</td>\n      <td>1.129033</td>\n      <td>0</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>351866</th>\n      <td>-1.079840</td>\n      <td>-0.087470</td>\n      <td>1.098917</td>\n      <td>1.688754</td>\n      <td>1.557515</td>\n      <td>-0.275749</td>\n      <td>-0.457411</td>\n      <td>-0.388187</td>\n      <td>-0.411264</td>\n      <td>-0.180158</td>\n      <td>0.422783</td>\n      <td>-0.041631</td>\n      <td>0</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1115045</th>\n      <td>-1.590770</td>\n      <td>0.142411</td>\n      <td>-0.909987</td>\n      <td>1.124173</td>\n      <td>-0.466375</td>\n      <td>-0.292969</td>\n      <td>-0.007738</td>\n      <td>-0.158052</td>\n      <td>0.908814</td>\n      <td>-0.859653</td>\n      <td>-0.486978</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81445</th>\n      <td>-0.057980</td>\n      <td>0.372293</td>\n      <td>-0.909987</td>\n      <td>0.996563</td>\n      <td>1.138779</td>\n      <td>-0.233963</td>\n      <td>-0.086252</td>\n      <td>-0.963524</td>\n      <td>1.495515</td>\n      <td>0.159590</td>\n      <td>1.332544</td>\n      <td>-1.212294</td>\n      <td>0</td>\n      <td>0.000003</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1105080</th>\n      <td>-0.568910</td>\n      <td>0.283193</td>\n      <td>1.098917</td>\n      <td>0.192228</td>\n      <td>-0.187218</td>\n      <td>-0.290813</td>\n      <td>1.583962</td>\n      <td>-0.042985</td>\n      <td>-1.291316</td>\n      <td>-1.199400</td>\n      <td>1.332544</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>838805</th>\n      <td>0.452949</td>\n      <td>-0.405876</td>\n      <td>-0.909987</td>\n      <td>-1.478312</td>\n      <td>0.999200</td>\n      <td>-0.267485</td>\n      <td>-0.136216</td>\n      <td>1.913160</td>\n      <td>-0.704615</td>\n      <td>-0.293407</td>\n      <td>0.422783</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.000002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1155691</th>\n      <td>1.219344</td>\n      <td>0.181556</td>\n      <td>1.098917</td>\n      <td>-0.399422</td>\n      <td>-1.583003</td>\n      <td>-0.293599</td>\n      <td>-0.814294</td>\n      <td>0.014549</td>\n      <td>-0.997965</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.000003</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>129668 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import metrics\ndef performance_assessment(predictions_df, output_feature='is_fraud', \n                           prediction_feature='predictions', rounded=True):\n    \n    AUC_ROC = metrics.roc_auc_score(predictions_df[output_feature], predictions_df[prediction_feature])\n    AP = metrics.average_precision_score(predictions_df[output_feature], predictions_df[prediction_feature])\n    \n    performances = pd.DataFrame([[AUC_ROC, AP]], \n                           columns=['AUC ROC','Average precision'])\n    performances = performances.round(3)\n    \n    return performances","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:49.404113Z","iopub.execute_input":"2023-02-11T17:56:49.404487Z","iopub.status.idle":"2023-02-11T17:56:49.413050Z","shell.execute_reply.started":"2023-02-11T17:56:49.404455Z","shell.execute_reply":"2023-02-11T17:56:49.412020Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"performance_assessment(predictions_df_AE)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T17:56:49.601910Z","iopub.execute_input":"2023-02-11T17:56:49.602270Z","iopub.status.idle":"2023-02-11T17:56:49.641426Z","shell.execute_reply.started":"2023-02-11T17:56:49.602239Z","shell.execute_reply":"2023-02-11T17:56:49.640261Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   AUC ROC  Average precision\n0     0.76               0.04","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AUC ROC</th>\n      <th>Average precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.76</td>\n      <td>0.04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluating the model on the testing set","metadata":{}},{"cell_type":"code","source":"df_test=pd.read_csv('../input/fraud-detection/fraudTest.csv')\ndf_test.drop_duplicates(inplace=True)\ndf_test = df_test.drop('Unnamed: 0', axis=1)\ndf_test['age']=dt.date.today().year-pd.to_datetime(df_test['dob']).dt.year\ndf_test['hour']=pd.to_datetime(df_test['trans_date_trans_time']).dt.hour\ndf_test['daily']=pd.to_datetime(df_test['trans_date_trans_time']).dt.day\ndf_test['day']=pd.to_datetime(df_test['trans_date_trans_time']).dt.dayofweek\ndf_test['month']=pd.to_datetime(df_test['trans_date_trans_time']).dt.month","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:04:12.750284Z","iopub.execute_input":"2023-02-11T18:04:12.751009Z","iopub.status.idle":"2023-02-11T18:04:17.400343Z","shell.execute_reply.started":"2023-02-11T18:04:12.750972Z","shell.execute_reply":"2023-02-11T18:04:17.399235Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"labelencoder1 = LabelEncoder()\ndf_test['category_encoded'] = labelencoder1.fit_transform(df_test['category'])\ndf_test['gender_encoded'] = labelencoder1.fit_transform(df_test['gender'])\ndf_test['city_encoded'] = labelencoder1.fit_transform(df_test['city'])\ndf_test['state_encoded'] =labelencoder1.fit_transform(df_test['state'])\ndf_test['job_encoded'] = labelencoder1.fit_transform(df_test['job'])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:04:17.405614Z","iopub.execute_input":"2023-02-11T18:04:17.407813Z","iopub.status.idle":"2023-02-11T18:04:18.354197Z","shell.execute_reply.started":"2023-02-11T18:04:17.407774Z","shell.execute_reply":"2023-02-11T18:04:18.353130Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"df_test = df_test[['category_encoded', 'amt', 'gender_encoded', 'city_encoded', 'state_encoded', 'city_pop', 'job_encoded', 'age', 'hour', 'daily', 'day', 'month', 'is_fraud']]","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:09:42.050863Z","iopub.execute_input":"2023-02-11T18:09:42.051227Z","iopub.status.idle":"2023-02-11T18:09:42.121066Z","shell.execute_reply.started":"2023-02-11T18:09:42.051197Z","shell.execute_reply":"2023-02-11T18:09:42.119955Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nscaler.fit(df_test[input_features])\n\ndf_test[input_features]=scaler.transform(df_test[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:09:50.434087Z","iopub.execute_input":"2023-02-11T18:09:50.434475Z","iopub.status.idle":"2023-02-11T18:09:50.583243Z","shell.execute_reply.started":"2023-02-11T18:09:50.434440Z","shell.execute_reply":"2023-02-11T18:09:50.582159Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[col] = igetitem(value, i)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test = df_test.iloc[:,:-1]\ny_test = df_test.iloc[:,-1]\nX_test_torch = torch.FloatTensor(X_test.values)\ny_test_torch = torch.FloatTensor(y_test.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:11:55.310992Z","iopub.execute_input":"2023-02-11T18:11:55.311541Z","iopub.status.idle":"2023-02-11T18:11:55.357681Z","shell.execute_reply.started":"2023-02-11T18:11:55.311491Z","shell.execute_reply":"2023-02-11T18:11:55.356695Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"test_set = FraudDataset(X_test_torch)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:12:19.098854Z","iopub.execute_input":"2023-02-11T18:12:19.099346Z","iopub.status.idle":"2023-02-11T18:12:19.109647Z","shell.execute_reply.started":"2023-02-11T18:12:19.099279Z","shell.execute_reply":"2023-02-11T18:12:19.108420Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"test_loader_params = {'batch_size': 64,\n              'num_workers': 0}\n    \ntest_generator = torch.utils.data.DataLoader(test_set, **test_loader_params)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:15:27.399801Z","iopub.execute_input":"2023-02-11T18:15:27.400154Z","iopub.status.idle":"2023-02-11T18:15:27.406250Z","shell.execute_reply.started":"2023-02-11T18:15:27.400123Z","shell.execute_reply":"2023-02-11T18:15:27.405022Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"test_losses = per_sample_mse(model, test_generator)\nprint(np.mean(test_losses))","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:15:29.475972Z","iopub.execute_input":"2023-02-11T18:15:29.476365Z","iopub.status.idle":"2023-02-11T18:15:44.816420Z","shell.execute_reply.started":"2023-02-11T18:15:29.476329Z","shell.execute_reply":"2023-02-11T18:15:44.815277Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"5.246954e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions_df_AE_test=df_test.copy()\npredictions_df_AE_test['predictions_loss']=test_losses","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:16:29.416707Z","iopub.execute_input":"2023-02-11T18:16:29.417059Z","iopub.status.idle":"2023-02-11T18:16:29.537239Z","shell.execute_reply.started":"2023-02-11T18:16:29.417028Z","shell.execute_reply":"2023-02-11T18:16:29.536280Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"predictions_df_AE_test['predictions'] = [1 if x > threshold_AE else 0 for x in predictions_df_AE_test['predictions_loss']]\npredictions_df_AE_test","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:17:42.734703Z","iopub.execute_input":"2023-02-11T18:17:42.735064Z","iopub.status.idle":"2023-02-11T18:17:42.980593Z","shell.execute_reply.started":"2023-02-11T18:17:42.735033Z","shell.execute_reply":"2023-02-11T18:17:42.979366Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"        category_encoded       amt  gender_encoded  city_encoded  \\\n0               0.961683 -0.424463        1.102494     -1.083619   \n1               0.961683 -0.252337       -0.907034     -1.659570   \n2              -0.316151 -0.179353       -0.907034     -1.475756   \n3               0.706116 -0.059605        1.102494      1.395827   \n4               1.728384 -0.422358        1.102494     -0.715991   \n...                  ...       ...             ...           ...   \n555714         -0.316151 -0.163467        1.102494      0.084621   \n555715          0.194983  0.270803        1.102494     -0.086939   \n555716          0.194983  0.111564       -0.907034     -1.300111   \n555717          1.728384 -0.391735        1.102494      0.219418   \n555718         -1.593986 -0.199449        1.102494     -0.809940   \n\n        state_encoded  city_pop  job_encoded       age      hour     daily  \\\n0            0.937072  0.816521     0.243860  0.307935 -0.118789  0.506526   \n1            1.220424 -0.292685     1.102086 -0.955089 -0.118789  0.506526   \n2            0.512044 -0.178853     0.126496  0.193114 -0.118789  0.506526   \n3           -1.258908 -0.111371     1.212115 -0.782859 -0.118789  0.506526   \n4           -0.338013 -0.289942    -0.335625  1.054267 -0.118789  0.506526   \n...               ...       ...          ...       ...       ...       ...   \n555714      -0.196337 -0.291963     1.600884  0.422755  1.496265  1.623183   \n555715       1.149586 -0.198018    -0.320955 -1.471781  1.496265  1.623183   \n555716       1.432939 -0.281427     0.383230 -0.438398  1.496265  1.623183   \n555717      -0.975555 -0.293261    -1.347891  0.480165  1.496265  1.623183   \n555718       0.653720  0.092477     0.251196 -1.127320  1.496265  1.623183   \n\n             day     month  is_fraud  predictions_loss  predictions  \n0       1.502388 -1.773597         0      5.989945e-06            0  \n1       1.502388 -1.773597         0      3.540982e-04            1  \n2       1.502388 -1.773597         0      7.627857e-07            0  \n3       1.502388 -1.773597         0      4.007259e-06            0  \n4       1.502388 -1.773597         0      3.679763e-06            0  \n...          ...       ...       ...               ...          ...  \n555714  0.125407  1.259458         0      2.389823e-06            0  \n555715  0.125407  1.259458         0      3.142831e-06            0  \n555716  0.125407  1.259458         0      2.007551e-06            0  \n555717  0.125407  1.259458         0      4.723286e-06            0  \n555718  0.125407  1.259458         0      2.706779e-06            0  \n\n[555719 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions_loss</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.961683</td>\n      <td>-0.424463</td>\n      <td>1.102494</td>\n      <td>-1.083619</td>\n      <td>0.937072</td>\n      <td>0.816521</td>\n      <td>0.243860</td>\n      <td>0.307935</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>5.989945e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.961683</td>\n      <td>-0.252337</td>\n      <td>-0.907034</td>\n      <td>-1.659570</td>\n      <td>1.220424</td>\n      <td>-0.292685</td>\n      <td>1.102086</td>\n      <td>-0.955089</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>3.540982e-04</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.316151</td>\n      <td>-0.179353</td>\n      <td>-0.907034</td>\n      <td>-1.475756</td>\n      <td>0.512044</td>\n      <td>-0.178853</td>\n      <td>0.126496</td>\n      <td>0.193114</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>7.627857e-07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.706116</td>\n      <td>-0.059605</td>\n      <td>1.102494</td>\n      <td>1.395827</td>\n      <td>-1.258908</td>\n      <td>-0.111371</td>\n      <td>1.212115</td>\n      <td>-0.782859</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>4.007259e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.728384</td>\n      <td>-0.422358</td>\n      <td>1.102494</td>\n      <td>-0.715991</td>\n      <td>-0.338013</td>\n      <td>-0.289942</td>\n      <td>-0.335625</td>\n      <td>1.054267</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>3.679763e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>555714</th>\n      <td>-0.316151</td>\n      <td>-0.163467</td>\n      <td>1.102494</td>\n      <td>0.084621</td>\n      <td>-0.196337</td>\n      <td>-0.291963</td>\n      <td>1.600884</td>\n      <td>0.422755</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>2.389823e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555715</th>\n      <td>0.194983</td>\n      <td>0.270803</td>\n      <td>1.102494</td>\n      <td>-0.086939</td>\n      <td>1.149586</td>\n      <td>-0.198018</td>\n      <td>-0.320955</td>\n      <td>-1.471781</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>3.142831e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555716</th>\n      <td>0.194983</td>\n      <td>0.111564</td>\n      <td>-0.907034</td>\n      <td>-1.300111</td>\n      <td>1.432939</td>\n      <td>-0.281427</td>\n      <td>0.383230</td>\n      <td>-0.438398</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>2.007551e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555717</th>\n      <td>1.728384</td>\n      <td>-0.391735</td>\n      <td>1.102494</td>\n      <td>0.219418</td>\n      <td>-0.975555</td>\n      <td>-0.293261</td>\n      <td>-1.347891</td>\n      <td>0.480165</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>4.723286e-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555718</th>\n      <td>-1.593986</td>\n      <td>-0.199449</td>\n      <td>1.102494</td>\n      <td>-0.809940</td>\n      <td>0.653720</td>\n      <td>0.092477</td>\n      <td>0.251196</td>\n      <td>-1.127320</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>2.706779e-06</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>555719 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performance_assessment(predictions_df_AE_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:18:19.667291Z","iopub.execute_input":"2023-02-11T18:18:19.668292Z","iopub.status.idle":"2023-02-11T18:18:19.792855Z","shell.execute_reply.started":"2023-02-11T18:18:19.668247Z","shell.execute_reply":"2023-02-11T18:18:19.791671Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"   AUC ROC  Average precision\n0     0.75              0.024","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AUC ROC</th>\n      <th>Average precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.75</td>\n      <td>0.024</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Isolation Forest VS AutoEncoder","metadata":{"execution":{"iopub.status.busy":"2023-01-01T14:09:41.476457Z","iopub.execute_input":"2023-01-01T14:09:41.476835Z","iopub.status.idle":"2023-01-01T14:09:41.488625Z","shell.execute_reply.started":"2023-01-01T14:09:41.476802Z","shell.execute_reply":"2023-01-01T14:09:41.487318Z"}}},{"cell_type":"markdown","source":"#### Isolation forests are an ensemble machine learning algorithm used for anomaly detection. They work by randomly partitioning the feature space and then making a decision tree. Points that are easier to isolate (i.e., require fewer splits) are considered to be anomalies. This approach is effective when the anomalies are well separated from the normal data points, and the anomalies are more scattered throughout the feature space.","metadata":{}},{"cell_type":"code","source":"df_val","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:30.923689Z","iopub.execute_input":"2023-02-11T18:19:30.924038Z","iopub.status.idle":"2023-02-11T18:19:30.947921Z","shell.execute_reply.started":"2023-02-11T18:19:30.924007Z","shell.execute_reply":"2023-02-11T18:19:30.946874Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n295133          -0.568910  0.216224       -0.909987     -0.337550   \n309036           0.197485 -0.231450        1.098917      1.251784   \n877558          -1.590770  0.604477       -0.909987      1.429666   \n696676          -0.313445 -0.098344       -0.909987      0.215430   \n351866          -1.079840 -0.087470        1.098917      1.688754   \n...                   ...       ...             ...           ...   \n1115045         -1.590770  0.142411       -0.909987      1.124173   \n81445           -0.057980  0.372293       -0.909987      0.996563   \n1105080         -0.568910  0.283193        1.098917      0.192228   \n838805           0.452949 -0.405876       -0.909987     -1.478312   \n1155691          1.219344  0.181556        1.098917     -0.399422   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n295133        0.929411 -0.248573    -1.206866  1.395357 -0.851290  1.065584   \n309036       -1.164268 -0.264084     1.555412  0.244683  1.348840  1.518580   \n877558        1.138779  0.183478     1.291318 -0.618322  1.202164  0.612587   \n696676        1.138779 -0.285640     0.634652  0.187150  0.615463  0.952334   \n351866        1.557515 -0.275749    -0.457411 -0.388187 -0.411264 -0.180158   \n...                ...       ...          ...       ...       ...       ...   \n1115045      -0.466375 -0.292969    -0.007738 -0.158052  0.908814 -0.859653   \n81445         1.138779 -0.233963    -0.086252 -0.963524  1.495515  0.159590   \n1105080      -0.187218 -0.290813     1.583962 -0.042985 -1.291316 -1.199400   \n838805        0.999200 -0.267485    -0.136216  1.913160 -0.704615 -0.293407   \n1155691      -1.583003 -0.293599    -0.814294  0.014549 -0.997965  1.292082   \n\n              day     month  is_fraud  \n295133   0.877664 -0.334296         0  \n309036  -0.486978 -0.334296         0  \n877558   0.877664  1.714365         0  \n696676  -0.032098  1.129033         0  \n351866   0.422783 -0.041631         0  \n...           ...       ...       ...  \n1115045 -0.486978 -0.626962         0  \n81445    1.332544 -1.212294         0  \n1105080  1.332544 -0.626962         0  \n838805   0.422783  1.714365         0  \n1155691 -1.396740 -0.626962         0  \n\n[129668 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295133</th>\n      <td>-0.568910</td>\n      <td>0.216224</td>\n      <td>-0.909987</td>\n      <td>-0.337550</td>\n      <td>0.929411</td>\n      <td>-0.248573</td>\n      <td>-1.206866</td>\n      <td>1.395357</td>\n      <td>-0.851290</td>\n      <td>1.065584</td>\n      <td>0.877664</td>\n      <td>-0.334296</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>309036</th>\n      <td>0.197485</td>\n      <td>-0.231450</td>\n      <td>1.098917</td>\n      <td>1.251784</td>\n      <td>-1.164268</td>\n      <td>-0.264084</td>\n      <td>1.555412</td>\n      <td>0.244683</td>\n      <td>1.348840</td>\n      <td>1.518580</td>\n      <td>-0.486978</td>\n      <td>-0.334296</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>877558</th>\n      <td>-1.590770</td>\n      <td>0.604477</td>\n      <td>-0.909987</td>\n      <td>1.429666</td>\n      <td>1.138779</td>\n      <td>0.183478</td>\n      <td>1.291318</td>\n      <td>-0.618322</td>\n      <td>1.202164</td>\n      <td>0.612587</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>696676</th>\n      <td>-0.313445</td>\n      <td>-0.098344</td>\n      <td>-0.909987</td>\n      <td>0.215430</td>\n      <td>1.138779</td>\n      <td>-0.285640</td>\n      <td>0.634652</td>\n      <td>0.187150</td>\n      <td>0.615463</td>\n      <td>0.952334</td>\n      <td>-0.032098</td>\n      <td>1.129033</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>351866</th>\n      <td>-1.079840</td>\n      <td>-0.087470</td>\n      <td>1.098917</td>\n      <td>1.688754</td>\n      <td>1.557515</td>\n      <td>-0.275749</td>\n      <td>-0.457411</td>\n      <td>-0.388187</td>\n      <td>-0.411264</td>\n      <td>-0.180158</td>\n      <td>0.422783</td>\n      <td>-0.041631</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1115045</th>\n      <td>-1.590770</td>\n      <td>0.142411</td>\n      <td>-0.909987</td>\n      <td>1.124173</td>\n      <td>-0.466375</td>\n      <td>-0.292969</td>\n      <td>-0.007738</td>\n      <td>-0.158052</td>\n      <td>0.908814</td>\n      <td>-0.859653</td>\n      <td>-0.486978</td>\n      <td>-0.626962</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81445</th>\n      <td>-0.057980</td>\n      <td>0.372293</td>\n      <td>-0.909987</td>\n      <td>0.996563</td>\n      <td>1.138779</td>\n      <td>-0.233963</td>\n      <td>-0.086252</td>\n      <td>-0.963524</td>\n      <td>1.495515</td>\n      <td>0.159590</td>\n      <td>1.332544</td>\n      <td>-1.212294</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1105080</th>\n      <td>-0.568910</td>\n      <td>0.283193</td>\n      <td>1.098917</td>\n      <td>0.192228</td>\n      <td>-0.187218</td>\n      <td>-0.290813</td>\n      <td>1.583962</td>\n      <td>-0.042985</td>\n      <td>-1.291316</td>\n      <td>-1.199400</td>\n      <td>1.332544</td>\n      <td>-0.626962</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>838805</th>\n      <td>0.452949</td>\n      <td>-0.405876</td>\n      <td>-0.909987</td>\n      <td>-1.478312</td>\n      <td>0.999200</td>\n      <td>-0.267485</td>\n      <td>-0.136216</td>\n      <td>1.913160</td>\n      <td>-0.704615</td>\n      <td>-0.293407</td>\n      <td>0.422783</td>\n      <td>1.714365</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1155691</th>\n      <td>1.219344</td>\n      <td>0.181556</td>\n      <td>1.098917</td>\n      <td>-0.399422</td>\n      <td>-1.583003</td>\n      <td>-0.293599</td>\n      <td>-0.814294</td>\n      <td>0.014549</td>\n      <td>-0.997965</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>129668 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\nanomalyclassifier = IsolationForest(random_state=SEED, n_estimators=40)\nanomalyclassifier.fit(df_train[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:34.460469Z","iopub.execute_input":"2023-02-11T18:19:34.460896Z","iopub.status.idle":"2023-02-11T18:19:37.461408Z","shell.execute_reply.started":"2023-02-11T18:19:34.460861Z","shell.execute_reply":"2023-02-11T18:19:37.460262Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"IsolationForest(n_estimators=40, random_state=42)"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df_IF = df_val.copy()\npredictions_df_IF['predictions_prob'] = -anomalyclassifier.score_samples(df_val[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:38.203909Z","iopub.execute_input":"2023-02-11T18:19:38.204384Z","iopub.status.idle":"2023-02-11T18:19:39.571539Z","shell.execute_reply.started":"2023-02-11T18:19:38.204341Z","shell.execute_reply":"2023-02-11T18:19:39.570529Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"threshold = np.percentile(predictions_df_IF['predictions_prob'],95)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:39.573451Z","iopub.execute_input":"2023-02-11T18:19:39.574150Z","iopub.status.idle":"2023-02-11T18:19:39.583763Z","shell.execute_reply.started":"2023-02-11T18:19:39.574110Z","shell.execute_reply":"2023-02-11T18:19:39.582691Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"predictions_df_IF['predictions'] = [1 if x > threshold else 0 for x in predictions_df_IF['predictions_prob']]\npredictions_df_IF","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:42.036779Z","iopub.execute_input":"2023-02-11T18:19:42.037149Z","iopub.status.idle":"2023-02-11T18:19:42.113109Z","shell.execute_reply.started":"2023-02-11T18:19:42.037118Z","shell.execute_reply":"2023-02-11T18:19:42.112229Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"         category_encoded       amt  gender_encoded  city_encoded  \\\n295133          -0.568910  0.216224       -0.909987     -0.337550   \n309036           0.197485 -0.231450        1.098917      1.251784   \n877558          -1.590770  0.604477       -0.909987      1.429666   \n696676          -0.313445 -0.098344       -0.909987      0.215430   \n351866          -1.079840 -0.087470        1.098917      1.688754   \n...                   ...       ...             ...           ...   \n1115045         -1.590770  0.142411       -0.909987      1.124173   \n81445           -0.057980  0.372293       -0.909987      0.996563   \n1105080         -0.568910  0.283193        1.098917      0.192228   \n838805           0.452949 -0.405876       -0.909987     -1.478312   \n1155691          1.219344  0.181556        1.098917     -0.399422   \n\n         state_encoded  city_pop  job_encoded       age      hour     daily  \\\n295133        0.929411 -0.248573    -1.206866  1.395357 -0.851290  1.065584   \n309036       -1.164268 -0.264084     1.555412  0.244683  1.348840  1.518580   \n877558        1.138779  0.183478     1.291318 -0.618322  1.202164  0.612587   \n696676        1.138779 -0.285640     0.634652  0.187150  0.615463  0.952334   \n351866        1.557515 -0.275749    -0.457411 -0.388187 -0.411264 -0.180158   \n...                ...       ...          ...       ...       ...       ...   \n1115045      -0.466375 -0.292969    -0.007738 -0.158052  0.908814 -0.859653   \n81445         1.138779 -0.233963    -0.086252 -0.963524  1.495515  0.159590   \n1105080      -0.187218 -0.290813     1.583962 -0.042985 -1.291316 -1.199400   \n838805        0.999200 -0.267485    -0.136216  1.913160 -0.704615 -0.293407   \n1155691      -1.583003 -0.293599    -0.814294  0.014549 -0.997965  1.292082   \n\n              day     month  is_fraud  predictions_prob  predictions  \n295133   0.877664 -0.334296         0          0.479600            0  \n309036  -0.486978 -0.334296         0          0.533265            0  \n877558   0.877664  1.714365         0          0.570037            1  \n696676  -0.032098  1.129033         0          0.472817            0  \n351866   0.422783 -0.041631         0          0.473646            0  \n...           ...       ...       ...               ...          ...  \n1115045 -0.486978 -0.626962         0          0.467666            0  \n81445    1.332544 -1.212294         0          0.521957            0  \n1105080  1.332544 -0.626962         0          0.484813            0  \n838805   0.422783  1.714365         0          0.490951            0  \n1155691 -1.396740 -0.626962         0          0.489703            0  \n\n[129668 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions_prob</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>295133</th>\n      <td>-0.568910</td>\n      <td>0.216224</td>\n      <td>-0.909987</td>\n      <td>-0.337550</td>\n      <td>0.929411</td>\n      <td>-0.248573</td>\n      <td>-1.206866</td>\n      <td>1.395357</td>\n      <td>-0.851290</td>\n      <td>1.065584</td>\n      <td>0.877664</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.479600</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>309036</th>\n      <td>0.197485</td>\n      <td>-0.231450</td>\n      <td>1.098917</td>\n      <td>1.251784</td>\n      <td>-1.164268</td>\n      <td>-0.264084</td>\n      <td>1.555412</td>\n      <td>0.244683</td>\n      <td>1.348840</td>\n      <td>1.518580</td>\n      <td>-0.486978</td>\n      <td>-0.334296</td>\n      <td>0</td>\n      <td>0.533265</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>877558</th>\n      <td>-1.590770</td>\n      <td>0.604477</td>\n      <td>-0.909987</td>\n      <td>1.429666</td>\n      <td>1.138779</td>\n      <td>0.183478</td>\n      <td>1.291318</td>\n      <td>-0.618322</td>\n      <td>1.202164</td>\n      <td>0.612587</td>\n      <td>0.877664</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.570037</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>696676</th>\n      <td>-0.313445</td>\n      <td>-0.098344</td>\n      <td>-0.909987</td>\n      <td>0.215430</td>\n      <td>1.138779</td>\n      <td>-0.285640</td>\n      <td>0.634652</td>\n      <td>0.187150</td>\n      <td>0.615463</td>\n      <td>0.952334</td>\n      <td>-0.032098</td>\n      <td>1.129033</td>\n      <td>0</td>\n      <td>0.472817</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>351866</th>\n      <td>-1.079840</td>\n      <td>-0.087470</td>\n      <td>1.098917</td>\n      <td>1.688754</td>\n      <td>1.557515</td>\n      <td>-0.275749</td>\n      <td>-0.457411</td>\n      <td>-0.388187</td>\n      <td>-0.411264</td>\n      <td>-0.180158</td>\n      <td>0.422783</td>\n      <td>-0.041631</td>\n      <td>0</td>\n      <td>0.473646</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1115045</th>\n      <td>-1.590770</td>\n      <td>0.142411</td>\n      <td>-0.909987</td>\n      <td>1.124173</td>\n      <td>-0.466375</td>\n      <td>-0.292969</td>\n      <td>-0.007738</td>\n      <td>-0.158052</td>\n      <td>0.908814</td>\n      <td>-0.859653</td>\n      <td>-0.486978</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.467666</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81445</th>\n      <td>-0.057980</td>\n      <td>0.372293</td>\n      <td>-0.909987</td>\n      <td>0.996563</td>\n      <td>1.138779</td>\n      <td>-0.233963</td>\n      <td>-0.086252</td>\n      <td>-0.963524</td>\n      <td>1.495515</td>\n      <td>0.159590</td>\n      <td>1.332544</td>\n      <td>-1.212294</td>\n      <td>0</td>\n      <td>0.521957</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1105080</th>\n      <td>-0.568910</td>\n      <td>0.283193</td>\n      <td>1.098917</td>\n      <td>0.192228</td>\n      <td>-0.187218</td>\n      <td>-0.290813</td>\n      <td>1.583962</td>\n      <td>-0.042985</td>\n      <td>-1.291316</td>\n      <td>-1.199400</td>\n      <td>1.332544</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.484813</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>838805</th>\n      <td>0.452949</td>\n      <td>-0.405876</td>\n      <td>-0.909987</td>\n      <td>-1.478312</td>\n      <td>0.999200</td>\n      <td>-0.267485</td>\n      <td>-0.136216</td>\n      <td>1.913160</td>\n      <td>-0.704615</td>\n      <td>-0.293407</td>\n      <td>0.422783</td>\n      <td>1.714365</td>\n      <td>0</td>\n      <td>0.490951</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1155691</th>\n      <td>1.219344</td>\n      <td>0.181556</td>\n      <td>1.098917</td>\n      <td>-0.399422</td>\n      <td>-1.583003</td>\n      <td>-0.293599</td>\n      <td>-0.814294</td>\n      <td>0.014549</td>\n      <td>-0.997965</td>\n      <td>1.292082</td>\n      <td>-1.396740</td>\n      <td>-0.626962</td>\n      <td>0</td>\n      <td>0.489703</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>129668 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performance_assessment(predictions_df_IF)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:43.426446Z","iopub.execute_input":"2023-02-11T18:19:43.427643Z","iopub.status.idle":"2023-02-11T18:19:43.471096Z","shell.execute_reply.started":"2023-02-11T18:19:43.427579Z","shell.execute_reply":"2023-02-11T18:19:43.469736Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"   AUC ROC  Average precision\n0    0.713              0.029","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AUC ROC</th>\n      <th>Average precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.713</td>\n      <td>0.029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluating the Isolation Forest model on the testing set","metadata":{}},{"cell_type":"code","source":"predictions_df_IF_test = df_test.copy()\npredictions_df_IF_test['predictions_prob'] = -anomalyclassifier.score_samples(df_test[input_features])","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:19:47.832126Z","iopub.execute_input":"2023-02-11T18:19:47.832498Z","iopub.status.idle":"2023-02-11T18:19:54.524774Z","shell.execute_reply.started":"2023-02-11T18:19:47.832466Z","shell.execute_reply":"2023-02-11T18:19:54.523731Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"predictions_df_IF_test['predictions'] = [1 if x > threshold else 0 for x in predictions_df_IF_test['predictions_prob']]\npredictions_df_IF_test","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:20:55.235809Z","iopub.execute_input":"2023-02-11T18:20:55.236235Z","iopub.status.idle":"2023-02-11T18:20:55.470346Z","shell.execute_reply.started":"2023-02-11T18:20:55.236199Z","shell.execute_reply":"2023-02-11T18:20:55.469258Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"        category_encoded       amt  gender_encoded  city_encoded  \\\n0               0.961683 -0.424463        1.102494     -1.083619   \n1               0.961683 -0.252337       -0.907034     -1.659570   \n2              -0.316151 -0.179353       -0.907034     -1.475756   \n3               0.706116 -0.059605        1.102494      1.395827   \n4               1.728384 -0.422358        1.102494     -0.715991   \n...                  ...       ...             ...           ...   \n555714         -0.316151 -0.163467        1.102494      0.084621   \n555715          0.194983  0.270803        1.102494     -0.086939   \n555716          0.194983  0.111564       -0.907034     -1.300111   \n555717          1.728384 -0.391735        1.102494      0.219418   \n555718         -1.593986 -0.199449        1.102494     -0.809940   \n\n        state_encoded  city_pop  job_encoded       age      hour     daily  \\\n0            0.937072  0.816521     0.243860  0.307935 -0.118789  0.506526   \n1            1.220424 -0.292685     1.102086 -0.955089 -0.118789  0.506526   \n2            0.512044 -0.178853     0.126496  0.193114 -0.118789  0.506526   \n3           -1.258908 -0.111371     1.212115 -0.782859 -0.118789  0.506526   \n4           -0.338013 -0.289942    -0.335625  1.054267 -0.118789  0.506526   \n...               ...       ...          ...       ...       ...       ...   \n555714      -0.196337 -0.291963     1.600884  0.422755  1.496265  1.623183   \n555715       1.149586 -0.198018    -0.320955 -1.471781  1.496265  1.623183   \n555716       1.432939 -0.281427     0.383230 -0.438398  1.496265  1.623183   \n555717      -0.975555 -0.293261    -1.347891  0.480165  1.496265  1.623183   \n555718       0.653720  0.092477     0.251196 -1.127320  1.496265  1.623183   \n\n             day     month  is_fraud  predictions_prob  predictions  \n0       1.502388 -1.773597         0          0.522183            0  \n1       1.502388 -1.773597         0          0.498364            0  \n2       1.502388 -1.773597         0          0.481281            0  \n3       1.502388 -1.773597         0          0.520492            0  \n4       1.502388 -1.773597         0          0.499005            0  \n...          ...       ...       ...               ...          ...  \n555714  0.125407  1.259458         0          0.519668            0  \n555715  0.125407  1.259458         0          0.507834            0  \n555716  0.125407  1.259458         0          0.508030            0  \n555717  0.125407  1.259458         0          0.531236            0  \n555718  0.125407  1.259458         0          0.530336            0  \n\n[555719 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_encoded</th>\n      <th>amt</th>\n      <th>gender_encoded</th>\n      <th>city_encoded</th>\n      <th>state_encoded</th>\n      <th>city_pop</th>\n      <th>job_encoded</th>\n      <th>age</th>\n      <th>hour</th>\n      <th>daily</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_fraud</th>\n      <th>predictions_prob</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.961683</td>\n      <td>-0.424463</td>\n      <td>1.102494</td>\n      <td>-1.083619</td>\n      <td>0.937072</td>\n      <td>0.816521</td>\n      <td>0.243860</td>\n      <td>0.307935</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>0.522183</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.961683</td>\n      <td>-0.252337</td>\n      <td>-0.907034</td>\n      <td>-1.659570</td>\n      <td>1.220424</td>\n      <td>-0.292685</td>\n      <td>1.102086</td>\n      <td>-0.955089</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>0.498364</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.316151</td>\n      <td>-0.179353</td>\n      <td>-0.907034</td>\n      <td>-1.475756</td>\n      <td>0.512044</td>\n      <td>-0.178853</td>\n      <td>0.126496</td>\n      <td>0.193114</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>0.481281</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.706116</td>\n      <td>-0.059605</td>\n      <td>1.102494</td>\n      <td>1.395827</td>\n      <td>-1.258908</td>\n      <td>-0.111371</td>\n      <td>1.212115</td>\n      <td>-0.782859</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>0.520492</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.728384</td>\n      <td>-0.422358</td>\n      <td>1.102494</td>\n      <td>-0.715991</td>\n      <td>-0.338013</td>\n      <td>-0.289942</td>\n      <td>-0.335625</td>\n      <td>1.054267</td>\n      <td>-0.118789</td>\n      <td>0.506526</td>\n      <td>1.502388</td>\n      <td>-1.773597</td>\n      <td>0</td>\n      <td>0.499005</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>555714</th>\n      <td>-0.316151</td>\n      <td>-0.163467</td>\n      <td>1.102494</td>\n      <td>0.084621</td>\n      <td>-0.196337</td>\n      <td>-0.291963</td>\n      <td>1.600884</td>\n      <td>0.422755</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>0.519668</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555715</th>\n      <td>0.194983</td>\n      <td>0.270803</td>\n      <td>1.102494</td>\n      <td>-0.086939</td>\n      <td>1.149586</td>\n      <td>-0.198018</td>\n      <td>-0.320955</td>\n      <td>-1.471781</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>0.507834</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555716</th>\n      <td>0.194983</td>\n      <td>0.111564</td>\n      <td>-0.907034</td>\n      <td>-1.300111</td>\n      <td>1.432939</td>\n      <td>-0.281427</td>\n      <td>0.383230</td>\n      <td>-0.438398</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>0.508030</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555717</th>\n      <td>1.728384</td>\n      <td>-0.391735</td>\n      <td>1.102494</td>\n      <td>0.219418</td>\n      <td>-0.975555</td>\n      <td>-0.293261</td>\n      <td>-1.347891</td>\n      <td>0.480165</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>0.531236</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>555718</th>\n      <td>-1.593986</td>\n      <td>-0.199449</td>\n      <td>1.102494</td>\n      <td>-0.809940</td>\n      <td>0.653720</td>\n      <td>0.092477</td>\n      <td>0.251196</td>\n      <td>-1.127320</td>\n      <td>1.496265</td>\n      <td>1.623183</td>\n      <td>0.125407</td>\n      <td>1.259458</td>\n      <td>0</td>\n      <td>0.530336</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>555719 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"performance_assessment(predictions_df_IF_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-11T18:21:16.531213Z","iopub.execute_input":"2023-02-11T18:21:16.531590Z","iopub.status.idle":"2023-02-11T18:21:16.654789Z","shell.execute_reply.started":"2023-02-11T18:21:16.531559Z","shell.execute_reply":"2023-02-11T18:21:16.653643Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"   AUC ROC  Average precision\n0    0.686              0.017","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AUC ROC</th>\n      <th>Average precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.686</td>\n      <td>0.017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"### Both autoencoders and isolation forests have their strengths and weaknesses, and the best choice for a particular problem will depend on the characteristics of the data and the specific requirements of the problem. In some cases, a combination of both techniques might produce the best results.\n\n### In conclusion, for the problem at hand, AutoEncoder was able to detect fraud more accuractly than our Isolation Forest (AUC_ROC Score of 0.75 vs 0.71 for validation set and 0.75 vs 0.69 for testing set)","metadata":{}}]}